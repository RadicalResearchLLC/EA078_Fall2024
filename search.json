[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Environmental Data Visualization - EA 078 Fall 2024",
    "section": "",
    "text": "Preface\nThis is the course website for ‘EA 078 PZ - Environmental Data Visualization’. In this course, you will learn to import, manipulate, and visualize data using R, with hands-on examples. You will also learn the theory and ethics of environmental data visualization. Throughout the course, you will have the opportunity to practice and apply the skills and judgment of data visualization to provide effective illustrations of real-world data in order to persuade, inform, and communicate.",
    "crumbs": [
      "Home",
      "Preface"
    ]
  },
  {
    "objectID": "index.html#preface",
    "href": "index.html#preface",
    "title": "Environmental Data Visualization - EA 078 Fall 2024",
    "section": "",
    "text": "This book is created using the Quarto publishing system in order to provide an example of its use in environmental data visualization and as a course resource tool for display of coding examples and visualization.",
    "crumbs": [
      "Home",
      "Preface"
    ]
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Environmental Data Visualization - EA 078 Fall 2024",
    "section": "License",
    "text": "License\nThis website is free to use, and is licensed under the Creative Commons Attribution-ShareAlike 4.0 License.",
    "crumbs": [
      "Home",
      "Preface"
    ]
  },
  {
    "objectID": "index.html#earth-selfie",
    "href": "index.html#earth-selfie",
    "title": "Environmental Data Visualization - EA 078 Fall 2024",
    "section": "Earth Selfie",
    "text": "Earth Selfie\nFigure 1 is the iconic Pale Blue Dot image taken by the Voyager 1 space probe in 1990 from beyond Neptune. The Earth in this image is only a single pixel in size.\n\n\n\n\n\nFigure 1: Carl Sagan’s Pale Blue Dot - an effective visualization?",
    "crumbs": [
      "Home",
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introductions",
    "section": "",
    "text": "Course Description\nThis is an introductory course on the theory and practice of effective communication with quantitative data. This course will introduce the theory of data visualization, discuss the ethics of data visualization, provide hands-on training in acquiring, tidying, and visualizing quantitative environmental data, and critically examine current environmental justice tools (CalEnviroScreen, EPA’s EJScreen, EPA’s EnviroAtlas, CEJST).",
    "crumbs": [
      "Home",
      "Introductions"
    ]
  },
  {
    "objectID": "intro.html#about-me",
    "href": "intro.html#about-me",
    "title": "Introductions",
    "section": "About Me",
    "text": "About Me\nCall me any of the following:\n\nMike\nDr. Mike\nProfessor Mike\nDr. McCarthy\nProfessor McCarthy\n\nMy pronouns are he/him. Here is some of my background.\n\nAdjunct Professor in Department of Environmental Analysis\nI have been an Environmental Consultant for ~20 years\n\ncurrently I am a sole proprietor at Radical Research LLC\nprior to that I worked at a company called Sonoma Technology, Inc.\n\nTrained as a chemist/atmospheric chemist\n\nundergrad at Creighton University\ngrad school at UC Berkeley\n\nIn my spare time, I enjoy\n\ngames (board, tabletop roleplaying, video games)\nyoga\nswimming\nfighting warehouse development in my neighborhood and the IE as Vice Chair of Riverside Neighbors Opposing Warehouses\n\nMy spouse is a Professor of Botany and Plant Sciences at UC Riverside, and my son is a student in middle school\nMy goals for this course\n\nbounce ideas around for cool new ways of looking at environmental data\nexplore and connect with your environmental interests\ncontinuously improve my teaching to better meet your needs\nlearn new ways of thinking about problems\nbuild tools to empower, inform, and persuade our communities",
    "crumbs": [
      "Home",
      "Introductions"
    ]
  },
  {
    "objectID": "intro.html#about-you",
    "href": "intro.html#about-you",
    "title": "Introductions",
    "section": "About You",
    "text": "About You\nNow it is your turn to introduce yourself. Please address the following four bullets. Please add anything else you think will be helpful for me and/or your colleagues to know about you.\n\nName (as you would like to be addressed)\nYear\nMajor/Field\nYour goal(s) for this course (if any)\nAn uninteresting factoid about you",
    "crumbs": [
      "Home",
      "Introductions"
    ]
  },
  {
    "objectID": "information.html",
    "href": "information.html",
    "title": "1  Fundamentals of Data Visualization",
    "section": "",
    "text": "1.1 Data, Information, and Knowledge",
    "crumbs": [
      "Home",
      "Unit 1: Introduction to Data Visualization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Fundamentals of Data Visualization</span>"
    ]
  },
  {
    "objectID": "information.html#data-information-and-knowledge",
    "href": "information.html#data-information-and-knowledge",
    "title": "1  Fundamentals of Data Visualization",
    "section": "",
    "text": "1.1.1 What is data?\n\nFacts, or discrete elements of information.\n\nquantitative or qualitative observations or descriptions\nstatistics or values represented in a form suitable for processing by computer\nplural of datum (never ever use this, IMO, everything is data, singular or plural)\n\n1.1.2 What is information?\n\nThe act of informing or the condition of being informed; communication of knowledge\n\nProcessed, stored, or transmitted data; structured data; data in context and significance\nStimuli that has meaning in some context for its receiver\n\n1.1.3 What is knowledge?\n\nGeneral understanding or familiarity with a subject\nAwareness of a subject; the state of being informed\nIntellectual understanding; the state of appreciating the truth of information",
    "crumbs": [
      "Home",
      "Unit 1: Introduction to Data Visualization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Fundamentals of Data Visualization</span>"
    ]
  },
  {
    "objectID": "information.html#weather-map-example",
    "href": "information.html#weather-map-example",
    "title": "1  Fundamentals of Data Visualization",
    "section": "\n1.2 Weather map example",
    "text": "1.2 Weather map example\n\n\n\n\n\nFigure 1.1: LA Times Weather Map\n\n\nThe visualization structures the underlying data into information. A good visualization communicates complex ideas with clarity, precision, and efficiency. It imparts knowledge.\n\n1.2.1 Categories of information illustrated by the newspaper weather visualization\n\n\nQuantitative (i.e., numerical) data\n\nTemperatures (high, low)\nPrecipitation\nWind speeds and directions\nAir quality index\nUV index\nTide heights and times\nSunrise & sunset times\n\n\n\nQualitative observations\n\n‘Seasonably warm’\n‘Fog, then mostly sunny’\nSky categories (partly cloudy, thunderstorms, rain, sunny, showers, fog, snow, ice)\nAir quality categories (e.g., unhealthy, moderate)\nFlood potential\nWarm front/cold front\nLow/high pressure\ndangerous rip currents risk is moderate/low\n\n\n\nSpatial\n\ngeographic properties\ntopology\ngeometric\ndistance\nprojections\n\n\n\n1.2.2 Data encodings\n\n\nGeometric primitives such as points, lines, and areas\n\nVisual channels such as size, color, shape, position, angle, and texture\n\nExamples of these encodings are shown in Figure 1.2.\n\n\n\n\n\nFigure 1.2: image credit: Nils Gehlenborg, ISMB/ECCB 2011\n\n\n\n\n\n\n\n\nWhy am I calling this information, and not data or insight?\nWhy isn’t this course called Environmental Information Visualization?",
    "crumbs": [
      "Home",
      "Unit 1: Introduction to Data Visualization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Fundamentals of Data Visualization</span>"
    ]
  },
  {
    "objectID": "information.html#abstraction",
    "href": "information.html#abstraction",
    "title": "1  Fundamentals of Data Visualization",
    "section": "\n1.3 Abstraction",
    "text": "1.3 Abstraction\nWhen we talk about the weather and use a data visualization, we are abstracting from Figure 1.3 to a 2-D representation of some numbers, colors, or pictures on a pixelized screen.\n\n\n\n\n\nFigure 1.3: Palm Springs\n\n\n🌩️🌩️🌩️🌩️🌩️🌩️🌩️🌩️🌩️🌩️🌩️🌩️🌩️🌩️🌩️🌩️🌩️🌩️🌩️🌩️🌩️🌩️🌩️\nData visualization is an artistic abstraction.\nAny environmental data visualization is not the thing itself. We are abstracting the thing itself in order to represent it in a condensed and structured way that conveys information. A thunderstorm emoji conveys the information about the weather in an abstract way, but is not the weather. However, we can put that thunderstorm emoji\n\non a map to provide spatial information\non a clock to provide temporal information\non a phone or an electronic device to communicate the weather in shorthand\n\nSimilarly, the abstraction of data into information allows for substantial control over the stylistic choices. Just like art has impressionism, realism, and surrealism, there are many different schools of thought about the appropriate ways to convey information.\nIn other words, the colors, symbols, shapes, and other stylistic choices encode and reveal truths about the data.",
    "crumbs": [
      "Home",
      "Unit 1: Introduction to Data Visualization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Fundamentals of Data Visualization</span>"
    ]
  },
  {
    "objectID": "information.html#ethics",
    "href": "information.html#ethics",
    "title": "1  Fundamentals of Data Visualization",
    "section": "\n1.4 Ethics",
    "text": "1.4 Ethics\n\n\n\n\n\n\nNote\n\n\n\nAvoid misrepresention!\n\n\nVisualization methods can, purposefully or inadvertently, distort the underlying data’s meaning. There are many underlying causes that can cause this distortion. Distortion can be caused (un)intentionly by the designer of the visualization. The other side is that the visualization may not be understandable to the user. Broadly, these problems can be categorized as:\n\n1.4.1 Spatial projection\n2-Dimensional cartographic representations (i.e., maps) distort either\n\n\nangles,\n\n\ndistances, or\n\nsizes\n\n1.4.2 Cognitive\nProblems associated with -\n\ngraphical elements - “Roses are red, violets are blue.”\nover-simplification - compare ozone alert images from KTLA news and the SCAQMD.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nunder-simplification\n\n\n\n\n\n\nFigure 1.4: Forward 24-hr wind trajectories from MacDonald et al., 2006, https://doi.org/10.1080/10473289.2006.10464509\n\n\n\nheterogeneity of intended audience (e.g., language barriers, color palettes for color-blindness).\n\n1.4.3 Emotional\n\nGraphical design or content may be repellent or triggering. In the syllabus, the COVID sneeze imagery is both factual model data and an intentionally gross way of visualizing the data to generate a feeling of disgust.\n\n\nA gross image of particles emissions from a sneeze\n\n\n1.4.4 Social\n\nCross-cultural norms -\n\ndirectionality of reading (left-to-right vs. right-to-left)\ncontext of color-scales (e.g., red-green in eastern vs. western cultures)\n\nUnderstanding the intended audience and their norms is always key to open and empathetic communication, whether through words or visualizations. Multiple visualizations may be required for communication with a diverse (i.e., heterogeneous) audience.",
    "crumbs": [
      "Home",
      "Unit 1: Introduction to Data Visualization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Fundamentals of Data Visualization</span>"
    ]
  },
  {
    "objectID": "information.html#what-is-the-baseline",
    "href": "information.html#what-is-the-baseline",
    "title": "1  Fundamentals of Data Visualization",
    "section": "\n1.5 What is the Baseline?",
    "text": "1.5 What is the Baseline?\nOne of the most common distortions is changing the scale of the axis to distort magnitudes. Here’s an example.\nThe code below loads some R packages that are useful for data processing and visualization.\n\nlibrary(data.table)\nlibrary(tidyverse)\nlibrary(plotly)\n\nThis code imports monthly mean Mauna Loa CO2 data from NOAA GMD CMDL, renames the columns, and then displays the bottom five rows to make sure it shows what we think it should.\n\nco2 &lt;- read_table('https://www.gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_mlo.txt',\n                  skip = 57 ) #%&gt;%\n\nfieldNames &lt;- c('year', 'month', 'decDate', 'meanCO2', 'trendedCO2', 'days', 'stdev', 'unc')\ncolnames(co2) &lt;- fieldNames\n\ntail(co2)\n\n# A tibble: 6 × 8\n   year month decDate meanCO2 trendedCO2  days stdev   unc\n  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  2024     2   2024.    425.       424.    22  1.24  0.51\n2  2024     3   2024.    425.       424.    22  0.99  0.4 \n3  2024     4   2024.    427.       424.    24  0.98  0.38\n4  2024     5   2024.    427.       424.    29  0.76  0.27\n5  2024     6   2024.    427.       424.    20  0.65  0.28\n6  2024     7   2025.    426.       425.    24  0.69  0.27\n\nhead(co2)\n\n# A tibble: 6 × 8\n   year month decDate meanCO2 trendedCO2  days stdev   unc\n  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  1959     7   1960.    317.       316.    -1 -9.99 -0.99\n2  1959     8   1960.    315.       316.    -1 -9.99 -0.99\n3  1959     9   1960.    314.       317.    -1 -9.99 -0.99\n4  1959    10   1960.    313.       316.    -1 -9.99 -0.99\n5  1959    11   1960.    315.       317.    -1 -9.99 -0.99\n6  1959    12   1960.    316.       316.    -1 -9.99 -0.99\n\n\nThe CO2 data is displayed in #fig-KeelingCurve1 and #fig-KeelingCurve2. How does the y-axis scale affect the interpretation of the same dataset?\n\nplot1 &lt;- co2 %&gt;% \n  ggplot(aes(x = decDate, y = meanCO2)) +\n  geom_line() +\n  theme_bw() +\n  labs(x = 'Year', y = 'Concentration CO2 (ppm)')\n\nggplotly(plot1)\n\n\n\n\n\n\nFigure 1.5: The Keeling Curve showing monthly average CO2 concentrations (ppm) at Mauna Loa\n\n\n\n\nplot2 &lt;- plot1 + \n  scale_y_continuous(limits = c(0,425))\n\nggplotly(plot2)\n\n\n\n\n\n\nFigure 1.6: The Keeling Curve showing monthly average CO2 concentrations (ppm) at Mauna Loa\n\n\n\nA longer viewpoint is shown in Figure 1.7 going back well beyond the late 1950s using CO2 data from ice cores, sediments, and other paleo-climatological sources. It shows another y-axis scale.\nHow do the three different y-axis scales distort the user impression of the data?\n\n\n\n\n\nFigure 1.7: HistoricalCO2",
    "crumbs": [
      "Home",
      "Unit 1: Introduction to Data Visualization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Fundamentals of Data Visualization</span>"
    ]
  },
  {
    "objectID": "information.html#color",
    "href": "information.html#color",
    "title": "1  Fundamentals of Data Visualization",
    "section": "\n1.6 Color",
    "text": "1.6 Color\nColor is fraught with peril and cultural associations. Moreover, roughly 10% of the population has some form of color-blindness.\n\n\n\n\n\n\nNote\n\n\n\nColor is very commonly used to manipulate the audience in environmental data visualization.\n\n\n\nBe cognizant of how choosing a color palette manipulates the audience\nDon’t use too many colors (rule of seven)\nBe aware of the three types of color palettes and choose the right one as in Figure 1.8.\n\ncontinuous sequential\ncategorical\ncontinuous diverging\n\n\n\n\n\n\n\n\nFigure 1.8: Rcolorbrewer color palettes\n\n\nHow does CalEnviroScreen look when changing from a Blues colorPalette to viridis magma?\n\n\n\n\n\n\n\n\n\n\n\n\n\nLooking for more on color palettes? Check out this Data Visualization Society post, or this color harmony blog post for marketing design.",
    "crumbs": [
      "Home",
      "Unit 1: Introduction to Data Visualization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Fundamentals of Data Visualization</span>"
    ]
  },
  {
    "objectID": "information.html#salience",
    "href": "information.html#salience",
    "title": "1  Fundamentals of Data Visualization",
    "section": "\n1.7 Salience",
    "text": "1.7 Salience\nVisual salience is the distinctive perceptual measure of how much a visual stimuli stands out from its surrounding neighbors to grab an observer’s attention.\nRead this!\n\n\n\n\n\n\nNote\n\n\n\nFocus on the pictures and captions to get an impression of visual salience. We’ll be using this as reading as a topic for discussion.",
    "crumbs": [
      "Home",
      "Unit 1: Introduction to Data Visualization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Fundamentals of Data Visualization</span>"
    ]
  },
  {
    "objectID": "coding1.html",
    "href": "coding1.html",
    "title": "2  Coding in R - Basics",
    "section": "",
    "text": "2.1 Overview",
    "crumbs": [
      "Home",
      "Unit 1: Introduction to Data Visualization",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Coding in R - Basics</span>"
    ]
  },
  {
    "objectID": "coding1.html#overview",
    "href": "coding1.html#overview",
    "title": "2  Coding in R - Basics",
    "section": "",
    "text": "Step 0 - Install R and RStudio\n\n\nStep 1 - Open RStudio \nA. Put in a header comment - who, when, what, where\nB. Install key packages\nC. Load key packages\n\n\nStep 2 - Acquire and/or Load Data\nA. Identify the path to the data\nB. Identify the data format\nC. Choose the right function to load the data - go to Step 1B and 1C again as needed D. Write code to import the data\nE. Run the code to import the data\n\nCheck for Error messages and warning messages in console; if failure, go back to Step 2D\n\nCheck to make sure data is loaded (look in Environment window)\nF. Step 2F - Look at the data - did it import correctly\n\nCheck column headers\n\nCheck data types\nG. Repeat Step 2 as needed for any other data required for visualization\n\n\n\n\nStep 3 - Tidy the data Advanced data science\n\n\nStep 4 - Visualize the data\nA. Choose the visualization type\nB. Choose the right functions\nC. Write code to do a basic visualization\nD. Add code to improve the visualization (repeat as needed)\nE. Annotate labels, axes, points, legends\nF. Export or publish the visualization\n\n\nStep 5 - Communicate with your audience using the visualization A. Get feedback from audience B. Revise visualization (Step 4D as needed) to improve for intended audience",
    "crumbs": [
      "Home",
      "Unit 1: Introduction to Data Visualization",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Coding in R - Basics</span>"
    ]
  },
  {
    "objectID": "coding1.html#example-1---mpg-dataset",
    "href": "coding1.html#example-1---mpg-dataset",
    "title": "2  Coding in R - Basics",
    "section": "\n2.2 Example 1 - mpg dataset",
    "text": "2.2 Example 1 - mpg dataset\n\n2.2.1 Step 1 - Open RStudio; install and load packages\n\n2.2.1.1 A. Open RStudio\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nOpening RStudio loads R.\nOpening R will not load RStudio.\n\n\nFigure 2.2 shows an annotated image of RStudio with the four panels labeled. In the default layout, the top-left is the text editor panel, the bottom-left is the console panel, the top-right is the files, plots, and packages panel, and the bottom-right is the environment panel.\n\n\n\n\n\nFigure 2.2: annotated.RStudio\n\n\n\nText Editor Panel - This is where you can enter code and have the editor color code it.\nConsole Panel - This is where errors and warnings appear when you run code. It can also be used to do direct coding, which I don’t recommend for beginners.\nFiles, plots, and packages panels - This is where files loaded in the working directory and packages in the default R directory are organized.\nEnvironment Panel - This is where data and variables you define in your coding will be organized\n\n2.2.1.2 Add a Header\nIt is good coding practice to put a basic header on your script.\nGo to the text editor and type #. Any line in an R script that starts with # is a comment and is not executable code. Lines starting with # will have a unique color.\nI usually add:\n\nName of project\n\nAuthor(s) of project\n\nMonth and Year created\n\nMonth and Year last modified\n\n2.2.1.3 Install and load packages\nType the following code into the text editor. This will download and install the tidyverse package onto your machine. Note that installing packages requires the package name in quotes.\n\ninstall.packages('ggplot2')\n\n\n\n\n\n\n\nPackages only need to be installed once.\n\n\n\nOnce that has completed, you will need to load the library using the library() function. In this call, the package name does not need to be quoted. Every time you open a session where you want to use a package, you need to run this code to load the package.\n\nlibrary(ggplot2)\n\nThe current libraries loaded can be founded in the file manager panel under the Packages tab.\n\n2.2.2 Step 2 - Acquire and/or Load Data\nIn this case we’re going go to do SUPER EZ mode. Acquiring and loading data has lots of detail oriented stuff, that we’re going to skip today to get to the fun stuff. We’ll jump into acquiring data and loading data on Friday.\nThe mpg dataset is an example dataset included in the tidyverse package. No loading required.\nWe can look at the first ten rows of the dataset by typing mpg and running that line of code.\n\nmpg\n\n# A tibble: 234 × 11\n   manufacturer model      displ  year   cyl trans drv     cty   hwy fl    class\n   &lt;chr&gt;        &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt;\n 1 audi         a4           1.8  1999     4 auto… f        18    29 p     comp…\n 2 audi         a4           1.8  1999     4 manu… f        21    29 p     comp…\n 3 audi         a4           2    2008     4 manu… f        20    31 p     comp…\n 4 audi         a4           2    2008     4 auto… f        21    30 p     comp…\n 5 audi         a4           2.8  1999     6 auto… f        16    26 p     comp…\n 6 audi         a4           2.8  1999     6 manu… f        18    26 p     comp…\n 7 audi         a4           3.1  2008     6 auto… f        18    27 p     comp…\n 8 audi         a4 quattro   1.8  1999     4 manu… 4        18    26 p     comp…\n 9 audi         a4 quattro   1.8  1999     4 auto… 4        16    25 p     comp…\n10 audi         a4 quattro   2    2008     4 manu… 4        20    28 p     comp…\n# ℹ 224 more rows\n\n\nThere are some key categorical variables (manufacturer, model, trans, cyl, class, year, drv) and others that are continuous variables (cty, hwy). As you may be able to guess, this data shows automobile average fuel efficiency in units of miles per gallon. We will using this dataset to showcase the grammar of graphical visualization in R.\n\n2.2.3 Step 3. Tidy the Data\nThis dataset is already reasonably tidy and so this step is not necessary for this example dataset. No munging is required.\n\n2.2.4 Step 4. Visualize the Data\nThe package ggplot is the most common graphics package within the tidyverse framework. It is extremely versatile, but requires an understanding of the grammar of graphics. ggplot is loaded as part of the tidyverse package.\n\n2.2.4.1 Choose the visualization type\nWe’ll be exploring point, line, and smoothed visualization types - geom_point, geom_line, ’geom_smooth`. In point plots, the individual data are shown as points. In line plots, individual points are connected by lines. In a smoothed plot, the points are usually shown with a curve attempting to fit the data to a model.\nThere are many more types of visualizations (text, histogram, box, bar, heatmaps, density, jitter, polygons, maps, quantiles, rasters, and violins) available, and we’ll explore the grammar for interesting ones in future classes.\n\n2.2.4.2 Choose the visualization function\n\n\nggplot()\n\ngeom_point()\ngeom_line()\ngeom_smooth()\n\n\n\nWe’ll apply ggplot() for every visualization for now, and add at least one geom function. We will then combine them to make fancier visualizations with overlays.\n\n2.2.4.3 Write the code to do a basic visualization\nCoding in the R tidyverse is a lot like writing a sentence, just in a foreign language that puts things in an order that may not be familiar.\n\nAdd a verb or two for an action - usually this is the function.\nAdd an object to apply the action to - this is usually the dataframe, but can be a list or another type of data object.\nAdd adjectives and adverbs to modify the action or the object\n\nFigure 2.3 shows a very basic visualization.\n\nggplot(data = mpg) +\n  geom_point(aes(x = displ, y = hwy))\n\n\n\n\n\n\nFigure 2.3: Basic visualization\n\n\n\n\nThis is a basic point plot. The x-axis shows engine displacement (Liters) for gasoline vehicles, and the y-axis shows highway driving fuel efficiency in miles per gallon.\nThree functions were used.\n\n\nggplot() - make a figure using mpg as the dataset\n\n\ngeom_point() - shows the data as points\n\n\naes() - aes is an abbreviation for aesthetics; map these variables for display\n\nIn the abstract, a code template for a basic graph is:\n\nggplot(data = &lt;DATA&gt;) + \n  &lt;GEOM_FUNCTION&gt;(mapping = aes(&lt;MAPPINGS&gt;))\n\nFigure 2.4 shows a basic line plot using geom_line instead of points. It is a visual abomination for this dataset. We’ll show why below.\n\nggplot(data = mpg) +\n  geom_line(aes(x = displ, y = hwy))\n\n\n\n\n\n\nFigure 2.4: Basic line visualization\n\n\n\n\nFigure 2.5 shows a smoothed line fit with geom_smooth.\n\nggplot(data = mpg) +\n  geom_smooth(aes(x = displ, y = hwy))\n\n\n\n\n\n\nFigure 2.5: Basic smooth visualization\n\n\n\n\n\n2.2.4.4 Noodle Zone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.2.4.5 Improve the Visualization\nThe basic visualization is in need of some improvement. First, let’s explore how the dataset looks by adding the aesthetics of color, then shape.\nFigure 2.6 shows the geom_point() plot with vehicle class in different colors. We do this by defining the category color = class within the aes().\n\nggplot(data = mpg) +\n  geom_point(aes(x = displ, y = hwy, color = class))\n\n\n\n\n\n\nFigure 2.6: Basic color visualization\n\n\n\n\nInteresting! The 2seater vehicle class gets better fuel efficiency then the SUV and pickups with similar displacement - likely because they are smaller. I also see that the subcompact and compact vehicle classes have the smallest engine displacement which is correlated with better fuel efficiency.\nFigure 2.7 uses a shape aesthetic instead of color.\n\nggplot(data = mpg) +\n  geom_point(aes(x = displ, y = hwy, shape = class))\n\nWarning: The shape palette can deal with a maximum of 6 discrete values because more\nthan 6 becomes difficult to discriminate\nℹ you have requested 7 values. Consider specifying shapes manually if you need\n  that many have them.\n\n\nWarning: Removed 62 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\nFigure 2.7: Basic shape visualization\n\n\n\n\nNotice anything missing? Our SUV class is gone because ggplot defaults to only allowing six individual shapes at a time. We can override this default.\nThe last new thing I want to show is a facet_wrap() which will make this visualization much easier to interpret on a class basis. Figure 2.8 shows how this works on our basic visualization by adding a line to our basic visualization.\n\nggplot(data = mpg) +\n  geom_point(aes(x = displ, y = hwy)) +\n  facet_wrap(~class)\n\n\n\n\n\n\nFigure 2.8: Basic color visualization\n\n\n\n\nThis helps us to better identify the individual classes of vehicles and understand the range of data available for each type of automobile.\n\n2.2.5 Putting It Together\nThe previous section shows examples for individual changes to our basic visualization. In this section, I’ll show you how easy it is to combine those lines.\n\n2.2.5.1 Example 1: Points and smooth\nFigure 2.9 shows a geom_point and geom_smooth overlaid on each other. We’ve also moved the aes function into the ggplot but could have put in both the geom_point and geom_smooth instead.\n\nggplot(data = mpg, aes(x = displ, y = hwy)) +\n  geom_point() +\n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\nFigure 2.9: Basic point and smooth visualization\n\n\n\n\n\n2.2.5.2 Example 2: Points, color, and smooth\nFigure 2.10 shows a geom_point and geom_smooth overlaid on each other but we’ve added the color for vehicle class as well. Unfortunately, the standard error on the smooth function is detracting from the graphic. Figure 2.11 removes that by specifying se = FALSE to the geom_smooth function and it makes the visualization much cleaner.\n\nggplot(data = mpg, aes(x = displ, y = hwy, color = class)) +\n  geom_point() +\n  geom_smooth()\n\n\n\n\n\n\nFigure 2.10: Basic point, color, and smooth visualization\n\n\n\n\n\nggplot(data = mpg, aes(x = displ, y = hwy, color = class)) +\n  geom_point() +\n  geom_smooth(se = FALSE)\n\n\n\n\n\n\nFigure 2.11: Basic point, color, and smooth visualization with standard error removed\n\n\n\n\n\n2.2.5.3 Example 3: Points, color, smooth, and facet\nThis last example will put it all together.\nFigure 2.12 shows a geom_point, geom_smooth, and facet_wrap overlaid on each other with the color for vehicle class as well. This figure combines most of what we’ve explored today in one figure. But we don’t need that legend if we already define each class separately!\nIn Figure 2.13 I remove the legend to make a final figure. This involves a function called theme() which specifies a lot of the meta components of a figure like fonts, legends, and the default look and feel of the figure. Here, I added a line of code that specifies theme(legend.position = 'none') to remove that redundant legend.\n\nggplot(data = mpg, aes(x = displ, y = hwy, color = class)) +\n  geom_point() +\n  geom_smooth(se = FALSE)+\n  facet_wrap(~class)\n\n\n\n\n\n\nFigure 2.12: Point, smooth, facet, and color visualization with standard error removed\n\n\n\n\n\nggplot(data = mpg, aes(x = displ, y = hwy, color = class)) +\n  geom_point() +\n  geom_smooth(se = FALSE)+\n  facet_wrap(~class) + \n  theme(legend.position = 'none')\n\n\n\n\n\n\nFigure 2.13: Point, smooth, facet, and color visualization with Legend and standard error removed\n\n\n\n\n\n2.2.6 In-Class Exercises\n\nCreate a point visualization with cty on the x-axis and hwy on the y-axis.\n\nFit that relationship by adding a geom_smooth()\n\nImprove that visualization by adding class as a color class\nImprove that visualization by adding a facet_wrap by a categorical variable of your choice\n\nFigure 2.14 shows the city-highway fuel efficiency relationship colored by class and faceted by cyl with the ugly gray background removed using theme_bw().\n\n\n\n\n\n\n\nFigure 2.14: Point, smooth, facet, and color visualization example\n\n\n\n\n\n2.2.6.1 Noodle Zone 2",
    "crumbs": [
      "Home",
      "Unit 1: Introduction to Data Visualization",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Coding in R - Basics</span>"
    ]
  },
  {
    "objectID": "maps1.html",
    "href": "maps1.html",
    "title": "3  Introduction to Spatial Visualization - 1",
    "section": "",
    "text": "3.1 Load and Install Packages\nAs a warmup, let’s load the tidyverse. Remember, you can check to make sure a package is loaded in your R session by checking on the files, plots, and packages panel, clicking on the Packages tab, and scrolling down to tidyverse to make sure it is checked.\n#library(tidyverse)",
    "crumbs": [
      "Home",
      "Unit 1: Introduction to Data Visualization",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to Spatial Visualization - 1</span>"
    ]
  },
  {
    "objectID": "maps1.html#load-and-install-packages",
    "href": "maps1.html#load-and-install-packages",
    "title": "3  Introduction to Spatial Visualization - 1",
    "section": "",
    "text": "3.1.1 Geospatial Packages\nR has multiple packages that enable geospatial data visualization. Today, we create basic maps using the sf and leaflet. sf stands for Simple Features which is an open-source geographic information systems data format that works pretty well with tidyverse. Leaflet is an open-source library for mobile-friendly interactive maps.\nAs a reminder, when we first use a package, we need to install it locally. Let’s start by installing both packages. This only needs to be done once.\n\ninstall.packages('sf')\ninstall.packages('leaflet')\n\nNext, we load the packages to make sure they are available within the R environment.\n\nlibrary(sf)\nlibrary(leaflet)\n\nInstalling and loading packages is EZ!",
    "crumbs": [
      "Home",
      "Unit 1: Introduction to Data Visualization",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to Spatial Visualization - 1</span>"
    ]
  },
  {
    "objectID": "maps1.html#acquiring-data",
    "href": "maps1.html#acquiring-data",
    "title": "3  Introduction to Spatial Visualization - 1",
    "section": "\n3.2 Acquiring Data",
    "text": "3.2 Acquiring Data\nWe are going to acquire two datasets for testing today. The first dataset is the nc shapefile dataset that should be installed as part of the sf package. Unlike mpg, this dataset is not directly available in the global environment.\nWe also will import geospatial environmental data set for our test examples. We are going to use a curated version of the CalEnviroscreen4.0 data. The data for the full state of California can be acquired as a zipped esri shapefile .shp. I’ve hosted a smaller version just for SoCal on my gitHub repository for this analysis. Downloading, unzipping, and then importing files is a big part of data science. Unfortunately, it has been my experience that having 15 people all have the same directory and file structures on 15 different machines is fraught with peril. I don’t want to troubleshoot that for an hour in class, so I tried to make the EZ mode code below.\n\n3.2.1 North Carolina shapefile\nWe will read the data in using the sf function st_read and the base R function system.file.\n\n\nst_read() is a specialized function that reads and loads in geospatial data files of various formats.\n\n\nsystem_file() is a function that checks for files that are within system directories that have been loaded as packages. It searches within the package directories on your computer.\n\n\nst_transform() is required to display the polygons properly in leaflet in the WGS84 coordinate reference system.\n\nWe assign the North Carolina data we’re reading into a dataset using the &lt;- operator. The &lt;- operator tells R that the data we are loading should be placed into a dataset that we have named nc. In future functions, nc will access that underlying data within nc.\nLastly, there is the pipe operator |&gt;. These pipes are amazing coding features that transformed coding for me. I cannot express my love for the |&gt; in words alone. It allows existing data or information to be passed to the next line of code after some operation has been done on the data. The pipe operator says, ‘take the output from this line of code, and now do this next thing’. I like to think of them as Super Mario pipes that Mario enters and is transported to another place. For now, take it on faith that this is the most useful operator in the tidyverse and will be littered throughout this course.\n\nnc &lt;- st_read(system.file(\"shape/nc.shp\", package=\"sf\")) |&gt; \n  st_transform(\"+proj=longlat +ellps=WGS84 +datum=WGS84\")\n\nReading layer `nc' from data source \n  `C:\\Users\\MichaelMcCarthy\\AppData\\Local\\R\\cache\\R\\renv\\cache\\v5\\R-4.4\\x86_64-w64-mingw32\\sf\\1.0-16\\ad57b543f7c3fca05213ba78ff63df9b\\sf\\shape\\nc.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 100 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax: 36.58965\nGeodetic CRS:  NAD27\n\n\nWe then use the head() function to print the first 5 rows of the nc dataset.\n\n\n\n\n\n\nPro tip: Always look at the data after import. Importing data is fraught with peril.\n\n\n\n\nhead(nc)\n\nSimple feature collection with 6 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -81.74091 ymin: 36.0729 xmax: -75.7728 ymax: 36.58973\nGeodetic CRS:  +proj=longlat +ellps=WGS84 +datum=WGS84\n   AREA PERIMETER CNTY_ CNTY_ID        NAME  FIPS FIPSNO CRESS_ID BIR74 SID74\n1 0.114     1.442  1825    1825        Ashe 37009  37009        5  1091     1\n2 0.061     1.231  1827    1827   Alleghany 37005  37005        3   487     0\n3 0.143     1.630  1828    1828       Surry 37171  37171       86  3188     5\n4 0.070     2.968  1831    1831   Currituck 37053  37053       27   508     1\n5 0.153     2.206  1832    1832 Northampton 37131  37131       66  1421     9\n6 0.097     1.670  1833    1833    Hertford 37091  37091       46  1452     7\n  NWBIR74 BIR79 SID79 NWBIR79                       geometry\n1      10  1364     0      19 MULTIPOLYGON (((-81.47258 3...\n2      10   542     3      12 MULTIPOLYGON (((-81.23971 3...\n3     208  3616     6     260 MULTIPOLYGON (((-80.45614 3...\n4     123   830     2     145 MULTIPOLYGON (((-76.00863 3...\n5    1066  1606     3    1197 MULTIPOLYGON (((-77.21736 3...\n6     954  1838     5    1237 MULTIPOLYGON (((-76.74474 3...\n\n\n\n3.2.2 Calenviroscreen4.0 geoJSON\nThe second dataset is hosted on the github repository where the class materials are version controlled. The code below names the internet URL where the data is stored as URL.path. If you go to the URL link, you will see the raw .geoJSON formatted spatial data file.\nNext, we apply the same st_read() function to read the geoJSON file. geoJSON is a common format for encoding geographic data structures, and st_read() natively knows how to read it in. The st_transform() function again changes the polygons into the WGS84 coordinate reference system.\nThis time, we’ve named the dataset SoCalEJ.\nFinally, we use the head() function on our SoCalEJ dataset to look at the first 5 rows.\n\nURL.path &lt;- 'https://raw.githubusercontent.com/RadicalResearchLLC/EDVcourse/main/CalEJ4/CalEJ.geoJSON'\nSoCalEJ &lt;- st_read(URL.path) |&gt; \n  st_transform(\"+proj=longlat +ellps=WGS84 +datum=WGS84\")\n\nReading layer `CalEJ' from data source \n  `https://raw.githubusercontent.com/RadicalResearchLLC/EDVcourse/main/CalEJ4/CalEJ.geoJSON' \n  using driver `GeoJSON'\nSimple feature collection with 3747 features and 66 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97418.38 ymin: -577885.1 xmax: 539719.6 ymax: -236300\nProjected CRS: NAD83 / California Albers\n\nhead(SoCalEJ)\n\nSimple feature collection with 6 features and 66 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -117.874 ymin: 33.5556 xmax: -117.7157 ymax: 33.64253\nGeodetic CRS:  +proj=longlat +ellps=WGS84 +datum=WGS84\n       Tract   ZIP County     ApproxLoc TotPop19   CIscore   CIscoreP\n1 6059062640 92656 Orange   Aliso Viejo     3741  9.642007 12.1028744\n2 6059062641 92637 Orange   Aliso Viejo     5376 10.569290 14.3343419\n3 6059062642 92625 Orange Newport Beach     2834  3.038871  0.6807867\n4 6059062643 92657 Orange Newport Beach     7231  6.538151  5.8497226\n5 6059062644 92660 Orange Newport Beach     8487  8.873604 10.4009077\n6 6059062645 92657 Orange Newport Beach     6527  6.033648  4.7402925\n       Ozone   OzoneP     PM2_5  PM2_5_P   DieselPM DieselPM_P  Pesticide\n1 0.05165298 65.36403  9.445785 43.88301 0.14536744   50.13068 0.00000000\n2 0.05219839 66.80772  9.785209 46.89484 0.07372588   27.41755 0.00000000\n3 0.04827750 55.38270 10.433417 52.03485 0.03478566   12.40821 0.06496406\n4 0.04901945 58.23273 10.013395 49.29683 0.03594981   12.90604 0.00000000\n5 0.04863521 56.96329 10.565404 52.63223 0.07701293   28.73678 0.00000000\n6 0.04863521 56.96329 10.329985 51.28811 0.04047264   14.58619 0.00000000\n  PesticideP   Tox_Rel Tox_Rel_P   Traffic TrafficP DrinkWat DrinkWatP\n1    0.00000  293.8420  41.44786  999.0182  57.7125 177.3831  5.907331\n2    0.00000  681.0703  57.65191 1051.9778  61.2250 312.7169 25.939803\n3   22.58621 1557.6400  74.05601  874.8193  49.5000 332.6654 32.284251\n4    0.00000 1349.2300  70.69267 1169.7532  67.4250 332.6654 32.284251\n5    0.00000 1889.5133  78.03201 1383.9867  74.9500 332.6654 32.284251\n6    0.00000 1589.1400  74.44361 1025.2790  59.5750 332.6654 32.284251\n       Lead    Lead_P Cleanup  CleanupP GWThreat GWThreatP HazWaste HazWasteP\n1 18.450498 10.737240     0.0  0.000000      0.0  0.000000    0.280  46.80344\n2  9.898042  3.730309     0.0  0.000000      0.0  0.000000    0.280  46.80344\n3 14.263664  6.830498     4.5 40.836133      2.0 14.311805    0.150  26.67108\n4  5.594984  1.600504     0.0  0.000000      0.5  2.722896    0.210  37.68365\n5 16.777373  9.061122     0.0  0.000000      7.5 39.448780    0.395  60.22502\n6 12.086059  5.343415     0.7  9.593132      2.0 14.311805    0.100  16.63799\n  ImpWatBod ImpWatBodP SolWaste SolWasteP PollBurd PolBurdSc PolBurdP Asthma\n1         7   66.73667        0   0.00000 30.50123  3.724194 18.95457  21.70\n2         7   66.73667        2  52.89805 35.23480  4.302163 29.71998  21.74\n3         8   72.15456        0   0.00000 35.68847  4.357555 30.77785  14.93\n4         6   58.69383        0   0.00000 30.97653  3.782228 19.87554  10.33\n5         2   23.87652        2  52.89805 39.48486  4.821094 41.44368  13.88\n6         3   33.15834        2  52.89805 32.98028  4.026885 24.04480  10.51\n     AsthmaP LowBirtWt   LowBirWP Cardiovas CardiovasP Educatn     EducatP\n1 11.2786640      4.45 37.2337696      9.74 27.5049850     1.0    1.771703\n2 11.3908275      3.50 16.2176033      8.72 18.8310070     8.4   35.876993\n3  3.7263210      1.18  0.2950988      5.41  1.8569292  -999.0 -999.000000\n4  0.9845464      5.39 61.9450860      4.46  0.3988036     2.0    5.859276\n5  2.7542373      2.86  7.6597383      5.43  1.9192423     3.7   14.781068\n6  1.0343968      4.64 42.1991275      4.65  0.4860419     0.0    0.000000\n  Ling_Isol Ling_IsolP Poverty  PovertyP Unempl     UnemplP HousBurd HousBurdP\n1       1.1   7.375829    20.0 34.208543    3.0   17.113483     19.9 62.420786\n2       4.4  33.942347    12.9 16.821608    2.6   11.868818     19.5 60.925222\n3       0.0   0.000000     9.5  8.982412    0.9    1.145237     14.5 35.817490\n4       3.9  30.694275     6.9  4.170854    2.6   11.868818      8.5  8.504436\n5       5.0  37.664095    12.3 15.326633    4.0   30.882353     18.9 58.225602\n6       1.0   6.266071    11.5 13.517588 -999.0 -999.000000     14.8 37.477820\n    PopChar PopCharSc   PopCharP Child_10 Pop_10_64 Elderly65 Hispanic   White\n1 24.958604 2.5890185 13.2375189  10.9864   81.7696    7.2441  16.4662 63.2184\n2 23.683405 2.4567389 11.7750882  13.2812   61.9792   24.7396  22.0238 55.2455\n3  6.722867 0.6973798  0.2647504   5.9280   49.6471   44.4248   5.6104 89.6260\n4 16.664505 1.7286508  4.9167927   7.9657   67.7361   24.2982   4.4530 63.9331\n5 17.743511 1.8405788  5.8119012  10.4866   72.3224   17.1910   8.8488 82.0785\n6 14.444279 1.4983412  3.3787191  11.0311   68.4388   20.5301   3.8302 74.7664\n  AfricanAm NativeAm OtherMult Shape_Leng Shape_Area    AAPI\n1    4.9452   0.0000    3.6087   5604.596    1467574 11.7616\n2    1.3765   0.0000    3.5900   6244.598    2143255 17.7641\n3    0.3881   0.0000    1.4467   6803.947    2048571  2.9287\n4    0.0000   0.3042    6.0987  26448.643   18729420 25.2109\n5    0.0000   0.0000    1.1076  10964.108    4361037  7.9651\n6    0.2911   0.0000    0.8733   9833.066    5754643 20.2390\n                        geometry\n1 MULTIPOLYGON (((-117.7178 3...\n2 MULTIPOLYGON (((-117.7166 3...\n3 MULTIPOLYGON (((-117.8596 3...\n4 MULTIPOLYGON (((-117.7986 3...\n5 MULTIPOLYGON (((-117.8521 3...\n6 MULTIPOLYGON (((-117.8269 3...\n\n\n\n\n\n\n\n\nSometimes the data import messes up at the end of the dataset. A thorough scholar will use the tail function to check the bottom 5 rows as well.\n\n\n\nIn future classes, we may dive into the perilous world of file structures and directories. However, that is unfun, unrewarding, and gruesomely detail oriented, so we’ll avoid it for now.\n\n3.2.3 Creating a New Geospatial Dataset\nIn addition to importing data, sometimes we just to create our own dataset. Let’s demonstrate how to create a very simple data frame in R for the latitude and longitude of a couple different locations we want to put on a map.\nI want to show the location of this classroom at the Redford Conservancy and the neighborhood where I live.\nI can use Google Maps or similar websites to get the latitude and longitude data. Latitude is North and South. Longitude is East and West.\n\nThe Redford Conservancy is at 34.1100576 N and -117.710074 W.\nMy zip code 92508 has a centroid at 33.8895145 N and -117.319014 W.\n\nThe code below will create a data frame which is an R data structure that has rows and columns. A data frame is a generic data object that can store tabular data of many different types.\nWe’ll use two base R functions to create the data frame, c() and data.frame().\n\n\nc() - this function concatenates data. It is used to create a list.\n’data.frame()` - this function turns a list (or lists) into a data.frame type.\n\nWe assign latitude values to a variable named lat, and a longitude values to a variable named lng. We use c() because we have multiple values that we want to include. We combine them into the locations data.frame. Then we check it worked by typing locations.\n\nlat &lt;- c(34.1100576, 33.8895145)\nlng &lt;- c(-117.710074, -117.319014)\n\nlocations &lt;- data.frame(lat, lng) \nlocations\n\n       lat       lng\n1 34.11006 -117.7101\n2 33.88951 -117.3190\n\n\n\n3.2.3.1 Exercise 1\n\nFind another location’s latitude and longitude coordinates that you want to add to a map.\nHack the code to add your location of interest to the two existing locations data.frame.\nDisplay the output of the locations data.frame to show that your code worked!",
    "crumbs": [
      "Home",
      "Unit 1: Introduction to Data Visualization",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to Spatial Visualization - 1</span>"
    ]
  },
  {
    "objectID": "maps1.html#visualize-the-data---geospatial-edition",
    "href": "maps1.html#visualize-the-data---geospatial-edition",
    "title": "3  Introduction to Spatial Visualization - 1",
    "section": "\n3.3 Visualize the Data - Geospatial Edition",
    "text": "3.3 Visualize the Data - Geospatial Edition\n\n3.3.1 Choose the visualization type\nWe’ll be exploring leaflet() maps for our visualizations. Leaflet has a number of in-built display functions for geospatial data that make things look really cool. I will note that ggplot can make maps too with geom_sf() and other functionality, but I prefer the leaflet tiles for interactive maps as a superior visualization tool.\n\n3.3.2 Choose the visualization function\n\n\nleaflet()\n\naddTiles()\naddMarkers()\naddPolygons()\naddLegends()\n\n\n\nWe’ll apply leaflet() to every visualization for geospatial data today, and add at least one add function to display spatial information.\n\n3.3.3 Write the code for a basic geospatial visualization\nLeaflet is a super cool package for making interactive maps with very few lines of code. As before let’s start with basics and then iterate.\nNote that Leaflet has a different style and coding aesthetic than ggplot, so some of the syntax and grammar is a bit different. However, the steps are the same as for ggplot.\n\nAdd a verb or two for an action - usually this is the function.\nAdd an object to apply the action to - this is usually the dataframe, but can be a list or another type of data object.\nAdd adjectives and adverbs to modify the action or the object\n\n\n3.3.3.1 Example 1 - Basic Tile Map\nFigure 3.2 shows the standard leaflet map with a minimal reproducible example. This map shows the whole world in a Mercator projection. The map is interactive, just like most of the maps you come across in standard apps and websites on the modern internet. You can zoom in and see the details of an area like Los Angeles, with all the annotation and standard roads, forests, city names, etc.\nThe code is simply two lines with two actionable functions.\n\n\nleaflet() - this function identifies the type of visualization.\n\naddTiles() - this function tells the leaflet map to display the default visualization ‘tile’. Tiles are the way geospatial data are rendered depending on the zoom level that makes it work for not displaying too much detail as you zoom out.\n\n\nleaflet() |&gt; \n  addTiles()\n\n\n\n\n\n\nFigure 3.2: A very basic Leaflet map\n\n\n\nA map is useful by itself, but we have not added any information to it. A map alone is not going to be useful as a visualization unless we add some data.\n\n3.3.3.2 Example 2. Tile Map with Location Markers\nRemember that locations data frame we created earlier. Let’s add that to the map.\naddMarkers() is a useful function to add point data to a map.\nFigure 3.3 shows the map with my two locations on it added as markers. We added another line of code with a pipe operator to put the locations data on the map.\n\nleaflet() |&gt; \n  addTiles() |&gt; \n  addMarkers(data = locations)\n\n\n\n\n\n\nFigure 3.3: Leaflet map with locations\n\n\n\nWhoot! A map with locations! And now the spatial extent of the map defaults to just show an area that encompasses the markers in the locations dataset. If your location that you added to the dataset happens to be outside California, your map will be zoomed way out compared to someone who only includes locations in SoCal.\n\n\n\n\n\n\nI purposely made the column names lat and lng because then we don’t have to assign those variables in the addMarkers call. If your columns are named something else (e.g., Lati or long), leaflet will need to be told that those are the correct columns to look for.\n\n\n\n\n3.3.3.3 Example 3. North Carolina Counties on a Tile Map\nGoing beyond point locations, geospatial data really shines when we display shapes. We’ll start by displaying the nc dataframe.\naddPolygons() is the function used to display polygons.\nFigure 3.4 shows the North Carolina counties.\n\nleaflet() |&gt; \n  addTiles() |&gt; \n  addPolygons(data = nc)\n\n\n\n\n\n\nFigure 3.4: Leaflet map with North Carolina Counties\n\n\n\nWe have done it!\n\n3.3.3.4 Exercise 2\n\nMake a leaflet map with the SoCalEJ dataset. It should look like Figure 3.5.\n\n\n\n\n\n\n\n\nFigure 3.5: Leaflet map with Calenviroscreen 4.0\n\n\n\n\n3.3.4 Improve the Visualization\nThe basic visualization is in need of some improvement. First let’s explore colors, fillcolors, stroke, and opacity.\nWithin the addPolygons() function, there are many options that can be modified to alter the output from the default settings. We won’t cover all these options today.\n\ncolor\nweight\nopacity\nfillColor\nfillOpacity\nstroke\ngroup\nlabel\n\nLet’s iterate and make some improvements!\nFigure 3.6 shows what happens we just change the color from blue to black. Both the fill and line color are changed.\n\nleaflet() |&gt; \n  addTiles() |&gt; \n  addPolygons(data = nc, color = 'black')\n\n\n\n\n\n\nFigure 3.6: Leaflet map with North Carolina Counties and color changed to black\n\n\n\nThe lines are too heavy. Let’s lower the weight - we’ll let the color go back to blue to keep the example minimal.\nFigure 3.7 shows the result, which is a much cleaner look.\n\nleaflet() |&gt; \n  addTiles() |&gt; \n  addPolygons(data = nc, weight = 1)\n\n\n\n\n\n\nFigure 3.7: Leaflet map for North Carolina Counties with line weight changed to 1.\n\n\n\nMuch better!\nWithin the North Carolina dataset are some numerical values by county. Let’s use fillcolor the counties to indicate the values.\nUnfortunately, leaflet requires us to do a bit of coding on our color palette.\nFunctions that help define the color palette in leaflet are\n\n\ncolorNumeric() - a linear color scale\n\ncolorQuantile() - a color scale that makes sure the bin sizes are approximately equal\n\ncolorFactor() - a color scale that is good for categorical (‘non-numeric’) data\n\nThis creates a numeric color palette for the BIR79 category of data for North Carolina in a numeric and quantile format. I have chosen the YlGn palette from Figure 1.8.\n\npal1 &lt;- colorNumeric(palette = 'YlGn', domain = nc$BIR79)\npal2 &lt;- colorQuantile(palette = 'YlGn', domain = nc$BIR79, n = 5)\n\nNow we see what those two palettes look like in the map. Figure 3.8 shows the default numeric palette, but it is too faint with the background tiles.\n\nleaflet() |&gt; \n  addTiles() |&gt; \n  addPolygons(data = nc,\n              weight = 1,\n              fillColor = ~pal1(BIR79))\n\n\n\n\n\n\nFigure 3.8: Leaflet map for North Carolina Counties with numeric palette for BIR79 and line weight = 1.\n\n\n\nIncreasing the fillOpacity to 0.8 will help us to see the data much better. Also, let’s remove the lines completely by setting stroke to FALSE. Figure 3.9 shows\n\nleaflet() |&gt; \n  addTiles() |&gt; \n  addPolygons(data = nc,\n              stroke = FALSE,\n              fillColor = ~pal1(BIR79),\n              fillOpacity = 0.8)\n\n\n\n\n\n\nFigure 3.9: Leaflet map for North Carolina Counties with numeric palette for BIR79, increasing opacity, removing lines.\n\n\n\nThat has a much better pop and we can really see the county differences in the high and low population areas.\nFigure 3.10 shows the quantile binned palette pal2. Now the number of counties in each color bin is about the same, which helps to sort the differences among the lowest population counties.\n\nleaflet() |&gt; \n  addTiles() |&gt; \n  addPolygons(data = nc, \n              stroke = FALSE,\n              fillColor = ~pal2(BIR79),\n              fillOpacity = 0.8)\n\n\n\n\n\n\nFigure 3.10: Leaflet map for North Carolina Counties with quantile palette for BIR79, opacity optimized, and lines removed.\n\n\n\n\n3.3.5 Exercise 3\n\nSelect a different color palette from Figure 1.8 to replace ‘YlGn’ in pal1.\nGenerate a North Carolina map with your choice of color palette for the BIR79 category.\n\n\n3.3.5.1 Adding a Legend\nThe existing map is not bad, but the color scale is not self-explanatory. We need to add a legend so a user can understand the data scale.\naddLegend() will provides that functionality.\nFigure 3.11 shows the legend overlay with the map. Note that we need to either move the data = nc into the initial call to leaflet() or define it separately in both the addPolygons and addLegend functions.\nThe addLegend polygon require the inputs for pal and values. Defining the color palette pal1 and the values of the scale ~BIR79 are required. The title is optional, but the scale doesn’t make much sense without a description.\n\nleaflet(data = nc) |&gt; \n  addTiles() |&gt; \n  addPolygons(stroke = FALSE,\n              fillColor = ~pal1(BIR79),\n              fillOpacity = 0.8) |&gt; \n  addLegend(pal = pal1, \n            title = 'Births in 1979', \n            values = ~BIR79)\n\n\n\n\n\n\nFigure 3.11: Leaflet map for North Carolina Counties with numeric palette for BIR79, color legend, opacity optimized, and lines removed.\n\n\n\n\n3.3.5.2 Noodle Zone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.3.5.3 Exercise 4\n\nCreate a colorPalette for a SoCalEJ dataset variable. Choose one of the following numerical variables and a colorPalette from Figure 1.8\n\n\n\nPoverty\nHispanic\nAfricanAm\nOzone\nDieselPM_P\n\n\nCreate a map for the SoCalEJ dataset with census tracts color coded for your chosen category of the following categories:\nAdd a Legend to the map\n\nThat map might look like Figure 3.12.\n\npalDPM &lt;- colorNumeric(palette = 'YlOrBr', domain = SoCalEJ$DieselPM_P, n = 5)\n\nleaflet(data = SoCalEJ) |&gt; \n  addTiles() |&gt; \n  setView(lat = 34, lng = -117.60, zoom = 9) |&gt; \n  addPolygons(stroke = FALSE,\n              fillColor = ~palDPM(DieselPM_P),\n              fillOpacity = 0.8) |&gt; \n  addLegend(pal = palDPM, \n            title = 'Diesel Particulate Matter (%)', \n            values = ~DieselPM_P)\n\n\n\n\n\n\nFigure 3.12: Leaflet map for Diesel PM percentile in Southern California",
    "crumbs": [
      "Home",
      "Unit 1: Introduction to Data Visualization",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to Spatial Visualization - 1</span>"
    ]
  },
  {
    "objectID": "maps2.html",
    "href": "maps2.html",
    "title": "4  Introduction to Spatial Visualization 2",
    "section": "",
    "text": "4.1 Load and Install Packages\nLoad ggplot2 and sf packages. Today we will be making static maps in ggplot2 which is part of the tidyverse ecosystem. We need the sf package to load, transform, and display geospatial data.\nlibrary(ggplot2)\nlibrary(sf)\n\nLinking to GEOS 3.12.1, GDAL 3.8.4, PROJ 9.3.1; sf_use_s2() is TRUE",
    "crumbs": [
      "Home",
      "Unit 1: Introduction to Data Visualization",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Introduction to Spatial Visualization 2</span>"
    ]
  },
  {
    "objectID": "maps2.html#acquire-data",
    "href": "maps2.html#acquire-data",
    "title": "4  Introduction to Spatial Visualization 2",
    "section": "\n4.2 Acquire Data",
    "text": "4.2 Acquire Data\nImport the nc and SoCalEJ datasets again. Refer to Chapter 3 for details on functions.\n\nnc &lt;- st_read(system.file(\"shape/nc.shp\", package=\"sf\")) |&gt; \n  st_transform(\"+proj=longlat +ellps=WGS84 +datum=WGS84\")\n\nReading layer `nc' from data source \n  `C:\\Users\\MichaelMcCarthy\\AppData\\Local\\R\\cache\\R\\renv\\cache\\v5\\R-4.4\\x86_64-w64-mingw32\\sf\\1.0-16\\ad57b543f7c3fca05213ba78ff63df9b\\sf\\shape\\nc.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 100 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax: 36.58965\nGeodetic CRS:  NAD27\n\ntail(nc)\n\nSimple feature collection with 6 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -79.07426 ymin: 33.88212 xmax: -76.28737 ymax: 35.01676\nGeodetic CRS:  +proj=longlat +ellps=WGS84 +datum=WGS84\n     AREA PERIMETER CNTY_ CNTY_ID        NAME  FIPS FIPSNO CRESS_ID BIR74 SID74\n95  0.125     2.868  2156    2156    Carteret 37031  37031       16  2414     5\n96  0.225     2.107  2162    2162      Bladen 37017  37017        9  1782     8\n97  0.214     2.152  2185    2185      Pender 37141  37141       71  1228     4\n98  0.240     2.365  2232    2232    Columbus 37047  37047       24  3350    15\n99  0.042     0.999  2238    2238 New Hanover 37129  37129       65  5526    12\n100 0.212     2.024  2241    2241   Brunswick 37019  37019       10  2181     5\n    NWBIR74 BIR79 SID79 NWBIR79                       geometry\n95      341  3339     4     487 MULTIPOLYGON (((-77.14865 3...\n96      818  2052     5    1023 MULTIPOLYGON (((-78.26123 3...\n97      580  1602     3     763 MULTIPOLYGON (((-78.02565 3...\n98     1431  4144    17    1832 MULTIPOLYGON (((-78.65546 3...\n99     1633  6917     9    2100 MULTIPOLYGON (((-77.96045 3...\n100     659  2655     6     841 MULTIPOLYGON (((-78.65546 3...\n\n\n\nURL.path &lt;- 'https://raw.githubusercontent.com/RadicalResearchLLC/EDVcourse/main/CalEJ4/CalEJ.geoJSON'\nSoCalEJ &lt;- st_read(URL.path) |&gt; \n  st_transform(\"+proj=longlat +ellps=WGS84 +datum=WGS84\")\n\nReading layer `CalEJ' from data source \n  `https://raw.githubusercontent.com/RadicalResearchLLC/EDVcourse/main/CalEJ4/CalEJ.geoJSON' \n  using driver `GeoJSON'\nSimple feature collection with 3747 features and 66 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97418.38 ymin: -577885.1 xmax: 539719.6 ymax: -236300\nProjected CRS: NAD83 / California Albers\n\ntail(SoCalEJ)\n\nSimple feature collection with 6 features and 66 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -118.2062 ymin: 33.96317 xmax: -117.9014 ymax: 34.16102\nGeodetic CRS:  +proj=longlat +ellps=WGS84 +datum=WGS84\n          Tract   ZIP      County    ApproxLoc TotPop19  CIscore CIscoreP\n3742 6037400602 91702 Los Angeles        Azusa     4250 32.63778 63.50227\n3743 6037430302 91016 Los Angeles     Monrovia     5339 17.12483 30.61019\n3744 6037430723 91007 Los Angeles      Arcadia     4365 13.84199 22.56682\n3745 6037431100 91016 Los Angeles     Monrovia     6758 39.69785 74.50832\n3746 6037533603 90201 Los Angeles         Bell     6986 62.93104 97.04992\n3747 6037534101 90201 Los Angeles Bell Gardens     2358 63.31505 97.22642\n          Ozone   OzoneP    PM2_5  PM2_5_P   DieselPM DieselPM_P Pesticide\n3742 0.06236471 88.69944 11.32762 58.23273 0.25141035   70.16801   0.00000\n3743 0.06236471 88.69944 11.87334 72.10952 0.03484052   12.43311   0.00000\n3744 0.05938691 79.98755 11.81607 70.24269 0.05856793   21.30678   0.00000\n3745 0.06133785 84.57996 11.89265 72.90604 0.52993389   90.91475   0.00000\n3746 0.04632538 46.99440 12.01973 79.45240 0.11636699   42.26509   0.00000\n3747 0.04716458 50.54138 12.02588 79.77598 0.89400714   97.51089  25.17289\n     PesticideP  Tox_Rel Tox_Rel_P   Traffic TrafficP DrinkWat DrinkWatP\n3742    0.00000 1128.208  66.72918  515.5913  22.0875 365.8082  37.91682\n3743    0.00000 1235.359  69.21730  471.5739  18.7625 570.8214  66.86649\n3744    0.00000 1324.937  70.43011 1003.0337  57.9875 667.6980  73.14850\n3745    0.00000 1575.716  74.35609 1560.1642  79.2625 497.7552  60.33471\n3746    0.00000 4435.870  91.04776 1071.6749  62.4000 639.0632  71.36256\n3747   67.58621 4409.633  90.89772 3653.6009  98.0750 514.1607  61.83340\n         Lead   Lead_P Cleanup  CleanupP GWThreat GWThreatP HazWaste HazWasteP\n3742 59.07638 64.54946    3.00 31.243001    46.85  89.10842    0.460  66.60490\n3743 71.04484 80.34026    1.40 19.914147     1.80  11.30666    0.320  52.64064\n3744 50.87304 52.71582    0.40  5.636432     5.00  30.88162    0.150  26.67108\n3745 54.59725 57.99622   43.50 94.438223    36.75  84.14411    1.885  92.15089\n3746 87.11610 94.82042   14.65 74.300112    17.05  63.42354    0.375  58.80874\n3747 90.85649 97.39130   20.35 82.232176    15.00  59.60485    1.110  86.60490\n     ImpWatBod ImpWatBodP SolWaste SolWasteP PollBurd PolBurdSc PolBurdP Asthma\n3742         0    0.00000     0.00  0.000000 46.49568  5.677114 60.95831  71.92\n3743         3   33.15834     0.25 11.592211 42.60985  5.202654 50.36714  48.33\n3744         0    0.00000     0.00  0.000000 39.69752  4.847059 42.02862  18.84\n3745         2   23.87652     8.75 87.949599 68.86648  8.408583 97.88426  46.90\n3746         7   66.73667     2.00 52.898053 61.77303  7.542474 93.03049  54.25\n3747         7   66.73667     0.20  9.667812 73.95742  9.030186 99.39017  52.71\n       AsthmaP LowBirtWt  LowBirWP Cardiovas CardiovasP Educatn  EducatP\n3742 79.847956      5.09 54.849885     17.02   76.34596    14.1 53.40420\n3743 53.950648      2.72  6.209905     11.22   39.70588     6.4 27.61326\n3744  7.614656      3.48 15.871183      7.73   11.83948     4.5 18.80537\n3745 51.856929      3.91 24.570182     10.87   36.88933    16.0 57.61832\n3746 62.076271      5.87 72.478830     23.93   96.68495    42.6 91.88813\n3747 59.895314      2.87  7.775212     23.15   95.45115    46.0 94.25462\n     Ling_Isol Ling_IsolP Poverty PovertyP Unempl   UnemplP HousBurd HousBurdP\n3742       5.6   40.89863    24.0 42.61307    2.9 15.838105     17.1  49.72117\n3743       7.0   48.72107    18.9 31.73367    1.2  1.900052     15.4  40.89987\n3744      13.6   73.09514    23.2 41.03015    4.0 30.882353     17.7  52.61090\n3745      10.1   62.24117    32.2 57.29899    6.2 59.383134     13.3  29.72117\n3746      21.7   88.69942    59.9 91.55779    9.1 82.326913     20.4  64.46134\n3747      11.7   67.72229    56.1 88.31658    9.3 83.224883     22.0  70.53232\n      PopChar PopCharSc PopCharP Child_10 Pop_10_64 Elderly65 Hispanic   White\n3742 55.42148  5.749009 58.49723  13.3882   74.3294   12.2824  68.1412 20.7294\n3743 31.73120  3.291557 22.33989   9.7584   72.7664   17.4752  28.7132 53.3995\n3744 27.52994  2.855750 16.50277  12.0504   77.4570   10.4926  10.9507 26.3918\n3745 45.51235  4.721110 43.58296  11.2607   81.4442    7.2951  58.2273 16.1438\n3746 80.43337  8.343554 92.93999  18.4226   72.1586    9.4188  91.4114  6.9425\n3747 67.59201  7.011489 76.72718  14.8431   75.0636   10.0933  91.0941  1.3147\n     AfricanAm NativeAm OtherMult Shape_Leng Shape_Area    AAPI\n3742    2.0941   0.3529    0.8941   6661.381  1537875.2  7.7882\n3743    1.5733   0.0000    7.1549   7166.131  1938015.8  9.1590\n3744    3.3677   0.0000    3.3677   3941.782   485563.0 55.9221\n3745    8.9967   0.0000    1.1098   8020.091  3015660.7 15.5223\n3746    0.6728   0.2577    0.7157   4949.117   811895.5  0.0000\n3747    1.9084   0.0000    0.0000   4420.127   509871.8  5.6828\n                           geometry\n3742 MULTIPOLYGON (((-117.9024 3...\n3743 MULTIPOLYGON (((-117.9917 3...\n3744 MULTIPOLYGON (((-118.0496 3...\n3745 MULTIPOLYGON (((-117.9987 3...\n3746 MULTIPOLYGON (((-118.1874 3...\n3747 MULTIPOLYGON (((-118.1636 3...\n\n\n\n4.2.1 Create a Locations Table\nI want to show the location of this classroom and my neighborhood. Let’s add locations again.\n\nlat &lt;- c(34.1100576, 33.8895145)\nlng &lt;- c(-117.710074, -117.319014)\n\nlocations &lt;- data.frame(lat, lng) \nlocations\n\n       lat       lng\n1 34.11006 -117.7101\n2 33.88951 -117.3190",
    "crumbs": [
      "Home",
      "Unit 1: Introduction to Data Visualization",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Introduction to Spatial Visualization 2</span>"
    ]
  },
  {
    "objectID": "maps2.html#visualize-the-data---geospatial-ggplot-edition",
    "href": "maps2.html#visualize-the-data---geospatial-ggplot-edition",
    "title": "4  Introduction to Spatial Visualization 2",
    "section": "\n4.3 Visualize the Data - Geospatial ggplot Edition",
    "text": "4.3 Visualize the Data - Geospatial ggplot Edition\nWhile the tidyverse doesn’t have all the features of leaflet, it can be a quick way to visualize geospatial data for static maps and there are times when adding a static ggplot map is sufficient and actually preferred to the more detailed leaflet maps.\nLet’s do a few example ggplot maps.\n\n4.3.1 Visualization functions\n\n\nggplot()\n\n\ngeom_sf() - display sf spatial data\n\ntheme_bw() - a cleaner background and visualization than default gray background for ggplot\n\n\ntheme_minimal() - minimalist theme\n\n\n\n4.3.2 Make a basic visualization\nStart with the North Carolina data and make a basic ggplot and geom_sf map as shown in Figure 4.2.\n\nggplot(data = nc) + \n  geom_sf()\n\n\n\n\n\n\nFigure 4.2: ggplot map for North Carolina counties\n\n\n\n\nNote that ggplot uses + rather than the magrittr |&gt; for connecting lines of code.\nIn contrast to the leaflet map, the ggplot defaults to showing the x- and y-axis coordinates (latitude and longitude), shows guidelines, and only draws the counties in the dataset, rather than defaulting to showing an interactive map.\nFigure 4.3 shows the same style of map replacing nc with SoCalEJ.\n\nggplot() + \n  geom_sf(data = SoCalEJ) \n\n\n\n\n\n\nFigure 4.3: ggplot map for census tracts in Inland SoCal counties\n\n\n\n\n\n4.3.3 Improve the Visualization\nWe have many options to improve a ggplot visualization. Let’s start by cleaning up the background using theme_bw(). theme_bw() changes the background from gray to a cleaner black-white style as shown in Figure 4.4.\n\nggplot() + \n  geom_sf(data = nc) +\n  theme_bw()\n\n\n\n\n\n\nFigure 4.4: ggplot map for North Carolina counties using theme_bw()\n\n\n\n\nWe can apply a minimalist aesthetic by choosing theme_minimal() as shown in Figure 4.5\n\nggplot() + \n  geom_sf(data = nc) +\n  theme_minimal()\n\n\n\n\n\n\nFigure 4.5: ggplot map for North Carolina counties using theme_bw()\n\n\n\n\nLet’s add colors in a ggplot way.\nUse aes(fill = &lt;VARIABLE NAME&gt;) to assign a category to color the counties by. The color palette to fill with is selected in scale_fill_&lt;TYPE&gt; where TYPE can be any of the following categories\n\nbinned\nbrewer\ncontinuous\ndate or datetime\ndiscrete\nfermenter\nviridis\n\nFirst let’s use the default palette for BIR79 to show the county birthrates in 1979. Adding fill = BIR79 to the aes() defaults to the Blues palette. Figure 4.6 shows the result of adding a fill color scale.\n\nggplot() + \n  geom_sf(data = nc, aes(fill = BIR79)) +\n  theme_bw() \n\n\n\n\n\n\nFigure 4.6: ggplot map for North Carolina counties using theme_bw() with fill\n\n\n\n\nLet’s change that to a viridis color scale. The function scale_fill_viridis_c() adds a fancier color-blind viridis palette in a continuous scale. Figure 4.7 shows this color scale option.\n\nggplot() + \n  geom_sf(data = nc, aes(fill = BIR79)) +\n  theme_bw() +\n  scale_fill_viridis_c()\n\n\n\n\n\n\nFigure 4.7: ggplot map for North Carolina counties using theme_bw() with viridis\n\n\n\n\nWe can also add other geoms, like points or labels to this map. Let’s try to label the counties.\nThe nc dataset has a variable called NAME for the county names. Figure 4.8 shows the figure when we add the county names using the function geom_sf_text().\n\nggplot(data = nc) + \n  geom_sf(aes(fill = BIR79)) +\n  geom_sf_text(aes(label = NAME), size = 1.5, color = 'white') +\n  theme_bw() +\n  scale_fill_viridis_c()\n\nWarning in st_point_on_surface.sfc(sf::st_zm(x)): st_point_on_surface may not\ngive correct results for longitude/latitude data\n\n\n\n\n\n\n\nFigure 4.8: ggplot map for North Carolina counties with names overlaid\n\n\n\n\nThere is a lot going on in that function. I made the text white color = ‘white’, the size of the font 1.5 size = 1.5, and added the label aesthetic with aes(label = NAME). If you remove the size or the color, you can see why those alterations were made.\n\n4.3.3.1 Exercise - Improve the SoCalEJ Visualization\n\nAdd a different theme from one of the theme options\n\nShow a variable (categorical, continuous, or quantile) using a fill option.\nAdd two or more SoCal locations to the map using geom_point and your locations table. If that is easy, try increasing the salience of the points through size, color, or shape modifications to that layer.\n\nFigure 4.9 shows a potential example of what that might look like.\n\n\n\n\n\n\n\nFigure 4.9: ggplot map for SoCal Diesel PM Percentile\n\n\n\n\nIt is really hard to see the details here. Let’s learn one last trick to zoom in on a ggplot to adjust the axes. The scale_x_continuous() and scale_y_continuous() functions allow us to set different axis limits. Figure 4.10 shows the\n\nggplot() + \n  geom_sf(data = SoCalEJ, aes(fill = DieselPM_P)) +\n  geom_point(data = locations,  aes(x = lng, y = lat), color = 'orange') +\n  theme_bw() +\n  scale_fill_viridis_c(option = 'A', direction = -1) +\n  scale_x_continuous(limits = c(-118, -117)) +\n  scale_y_continuous(limits = c(33.7, 34.2))\n\n\n\n\n\n\nFigure 4.10: ggplot map for SoCal Diesel PM Percentile zoomed into Claremont and Ontario.\n\n\n\n\n\n4.3.3.2 Noodle Zone\nOnly includes nc data at this point. Can add SoCalEJ if needed.",
    "crumbs": [
      "Home",
      "Unit 1: Introduction to Data Visualization",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Introduction to Spatial Visualization 2</span>"
    ]
  },
  {
    "objectID": "chartJunk.html",
    "href": "chartJunk.html",
    "title": "5  Chartjunk, Data-Ink Ratios, and Visualization Theory",
    "section": "",
    "text": "5.1 Chartjunk\nChart Junk is a term first used by Edward Tufte in his book The Quantitative Display of Visual Information. He defined it as:\nIn other words, Tufte believes that embellishment, decoration, and ornamentation is typically bad in a data visualization. While I can talk about this, it is better to just show examples of chartjunk.\nJust do an image search for chartjunk in your browser. Here’s a few examples.\nFigure 5.1 shows a very simple bar chart with lots of colors, patterns, and\nFigure 5.2 shows a price line chart embellished with a decorative reclining lady. This is what Tufte calls a Duck - elevating design over data.\nFigure 5.3 shows a pie chart of video analysis by medical professionals. Only three values are shown, yet there is a flourish of colors, cartoons, clipart, and embellishment.\nTufte was pretty crufty about anything that was not minimalist. He is an pro-modernist design and anti-baroque design. And there is some research that suggests more ornamented and interesting visualizations stick with people longer than minimal designs.",
    "crumbs": [
      "Home",
      "Unit 1: Introduction to Data Visualization",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chartjunk, Data-Ink Ratios, and Visualization Theory</span>"
    ]
  },
  {
    "objectID": "chartJunk.html#chartjunk",
    "href": "chartJunk.html#chartjunk",
    "title": "5  Chartjunk, Data-Ink Ratios, and Visualization Theory",
    "section": "",
    "text": "The interior decoration of graphics generates a lot of ink that does not tell the viewer anything new. The purpose of decoration varies-to make the graphic appear more scientific and precise, to enliven the display, to give the designer an opportunity to exercise artistic skills. Regardless of its cause it is all non-data-ink or redundant data-ink, and it is often chartjunk.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 5.1: Mario looking bar chart\n\n\n\n\n\n\n\n\n\n\nFigure 5.2: Infamous diamonds line\n\n\n\n\n\n\n\n\n\n\nFigure 5.3: Pie Chartjunk",
    "crumbs": [
      "Home",
      "Unit 1: Introduction to Data Visualization",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chartjunk, Data-Ink Ratios, and Visualization Theory</span>"
    ]
  },
  {
    "objectID": "chartJunk.html#data-ink-ratios",
    "href": "chartJunk.html#data-ink-ratios",
    "title": "5  Chartjunk, Data-Ink Ratios, and Visualization Theory",
    "section": "5.2 Data-Ink Ratios",
    "text": "5.2 Data-Ink Ratios\nThe second Tufte-ism is the ratio of data-ink. This is a quantitative measure indicating the amount of ‘ink’ used to convey data/information in a visualization. Any ‘ink’ not conveying information is considered superfluous and redundant.\n\n\n\nData Ink Ratio\n\n\nA simple example from the tidyverse would be to compare the default theme for a ggplot() with theme_bw() or theme_minimal().\nHere’s Figure 4-2 with the default theme. Notice all that background ‘ink’ in gray.\nTufte would definitely prefer Figure 45-5 where we removed all that background and even the frame around the outside of the map.\nThis is an aesthetic preference, especially in the modern era where almost all of the visualization we engage with is on a computer/tablet/phone. There is no amount of pixel-ink that is consumed. And in some cases the brightness of a white background may be antithetical and harmful, such as in the ProPublica Sacrifice Zone visualizations as shown in Figure 17.2.",
    "crumbs": [
      "Home",
      "Unit 1: Introduction to Data Visualization",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chartjunk, Data-Ink Ratios, and Visualization Theory</span>"
    ]
  },
  {
    "objectID": "chartJunk.html#what-makes-a-map-in-leaflet-bad",
    "href": "chartJunk.html#what-makes-a-map-in-leaflet-bad",
    "title": "5  Chartjunk, Data-Ink Ratios, and Visualization Theory",
    "section": "5.3 What makes a map in leaflet bad?",
    "text": "5.3 What makes a map in leaflet bad?\nMost of the teams are using leaflet maps. What things in leaflet look bad and don’t work?\nDiscuss",
    "crumbs": [
      "Home",
      "Unit 1: Introduction to Data Visualization",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chartjunk, Data-Ink Ratios, and Visualization Theory</span>"
    ]
  },
  {
    "objectID": "chartJunk.html#class-exercise---work-on-group-visualization",
    "href": "chartJunk.html#class-exercise---work-on-group-visualization",
    "title": "5  Chartjunk, Data-Ink Ratios, and Visualization Theory",
    "section": "5.4 Class Exercise - work on group visualization",
    "text": "5.4 Class Exercise - work on group visualization\nHere’s a framework for the final group visualization from the Junk Charts Blog\n\nWhat is the practical question?\nWhat does the data you have say about the question?\nWhat do the individual visualizations say?\n\nI would add:\n\nWho is the audience for the visualization?",
    "crumbs": [
      "Home",
      "Unit 1: Introduction to Data Visualization",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chartjunk, Data-Ink Ratios, and Visualization Theory</span>"
    ]
  },
  {
    "objectID": "assignment1.html",
    "href": "assignment1.html",
    "title": "6  Assignments for Unit 1",
    "section": "",
    "text": "6.1 Graded Assignment - Visualization Critique Paper\nChoose a environmental data visualization. This can include static figures, interactive graphics, infographics, apps, videos, animations, etc. Please get approval from Mike if you are choosing something that may not meet a standard definition of an environmental data visualization.\nWrite a two-page paper (12-point font or less) describing the visualization and salient features that you think are interesting and noteworthy. Include a picture or link to your chosen visualization (does not count towards 2-page minimum). In your critique, please include ten individual points that fit into at least one of these categories. Include at least 3 of these categories in your paper.\nAssignment is due September 5, 2024 at the beginning of class (9:45 AM). Assignments can be emailed or physically turned in. This assignment is worth 150 points. Spelling, grammar, and sentence structure will be a minor component of the score (~10 points).",
    "crumbs": [
      "Home",
      "Unit 1: Introduction to Data Visualization",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Assignments for Unit 1</span>"
    ]
  },
  {
    "objectID": "assignment1.html#graded-assignment---visualization-critique-paper",
    "href": "assignment1.html#graded-assignment---visualization-critique-paper",
    "title": "6  Assignments for Unit 1",
    "section": "",
    "text": "Things that you like, or think are done well\nThings that you dislike, or think are done poorly\nImprovements you would make to the visualization (can be additions or subtractions from features in the visualization)\nFeatures that provide interesting structure to the data and make it more informative\nFeatures that you find aid in communicating knowledge or help tell the story.",
    "crumbs": [
      "Home",
      "Unit 1: Introduction to Data Visualization",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Assignments for Unit 1</span>"
    ]
  },
  {
    "objectID": "EJtheory.html",
    "href": "EJtheory.html",
    "title": "7  EJ - Screening Tools",
    "section": "",
    "text": "7.1 Definitions",
    "crumbs": [
      "Home",
      "Unit 2: Environmental Justice",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>EJ - Screening Tools</span>"
    ]
  },
  {
    "objectID": "EJtheory.html#definitions",
    "href": "EJtheory.html#definitions",
    "title": "7  EJ - Screening Tools",
    "section": "",
    "text": "Environmental Protection Agency and California EPA - The fair treatment and meaningful involvement of all people regardless of race, color, culture, national origin, income, and educational levels with respect to the development, implementation, and enforcement of protective environmental laws, regulations, and policies. Fair treatment means that no population, due to policy or economic disempowerment, is forced to bear a disproportionate burden of the negative human health or environmental impacts of pollution or other environmental consequences resulting from industrial, municipal, and commercial operations or the execution of federal, state, local, and tribal programs and policies\nSchlosberg et al., 2002 - - The equitable distribution of environmental risks and benefits\nThe difference between Environmentalism and Environmental Justice is that Environmental Justice brings forward the underlying issues of race, ethnicity, class, wealth, and/or sovereignty in environmental decision-making.\n\n\n7.1.1 Discussion 1\n\nIs there anything missing from these definitions of Environmental Justice?\nHow does the EPA’s focus on the negative impacts frame Environmental Justice?\nIs a focus on equitable distribution possible in the United States, California, or local municipalities?",
    "crumbs": [
      "Home",
      "Unit 2: Environmental Justice",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>EJ - Screening Tools</span>"
    ]
  },
  {
    "objectID": "EJtheory.html#concepts-of-environmental-justice-movement",
    "href": "EJtheory.html#concepts-of-environmental-justice-movement",
    "title": "7  EJ - Screening Tools",
    "section": "7.2 Concepts of Environmental Justice Movement",
    "text": "7.2 Concepts of Environmental Justice Movement\nThe Environmental Justice is a broad and diffuse global movement with many facets. We will not be able to cover most of these concepts in-depth due to time constraints and the visualization focus of this course.\nI did want to do an overview of these topics such that we can compare them to the current tools used in the U.S. and California for measuringing and quantifying Environmental Justice.\n\nEnvironmental Racism - racial discrimination in environmental policy making, enforcement, and decision-making. This applies both within the United States and globally (e.g., hazardous waste export to southern hemisphere).\nEcological debt - the accumulation of obligations through inequitable resource exploitation, pollution, and habitat degradation between the Northern and Southern hemisphere. This has been quantified through climate debt which examines emissions differentials in carbon budgets and adaptation costs which will accrue primarily to poorer countries.\nClimate justice - equitable distribution of benefits and burdens of climate change adaptation and costs.\nFood sovereignty - a food system in which the people who produce, distribute, and consume food also control the mechanisms and policies of food production and distribution; this stands in contrast to a corporate food regime in which corporations and market insitutions control the food system.\n\nSacrifice Zones - a geographic area permanently impaired by heavy environmental alterations or economic disinvestment, often through locally unwanted land use (LULU).\nEnvironmentalism of the poor - social movement that emphasizes social justice issues instead of emphasizing conservation and eco-efficiency; focuses on sustainability and sovereignty.",
    "crumbs": [
      "Home",
      "Unit 2: Environmental Justice",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>EJ - Screening Tools</span>"
    ]
  },
  {
    "objectID": "EJtheory.html#environmental-justice-tools",
    "href": "EJtheory.html#environmental-justice-tools",
    "title": "7  EJ - Screening Tools",
    "section": "7.3 Environmental Justice Tools",
    "text": "7.3 Environmental Justice Tools\nWe are going to be talking about four EJ tools in this course.\n\nCalEnviroScreen4.0\nEJScreen\nEJI\nClimate and Economic Justice Tool\n\nFor today, I want to focus on the intersection of the concepts of environmental justice listed above and the metrics of environmental justice in these tools.\n\n7.3.1 CalEnviroScreen\n\n\n\n\n\n\nFigure 7.1: CalEnviroScreen Pollution Burden\n\n\n\nFigure 7.1 shows the CalEnviroScreen tool pollution burden index for SoCal. The CalEnviroScreen tool is made up of two categories of data indicators, as documented in the 207 page CalEnviroScreen4.0 report.\n\nPollution Burden - negative environmental indicators of either pollution exposure or environmental effects (e.g., ozone, PM, traffic, drinking water contaminants, toxic release facilities)\nPopulation Characteristics - health and socio-economic indicators (e.g., asthma, education, unemployment, low birth weight) - economic, educational, and linguistic indicators are included.\n\nThe Pollution Burden score and Population Characteristics score are multiplied to determine the final CalEnviroScreen Score.\nCalEnviroScreen4.0 does not have race/ethnicity explicitly as an explanatory variable or part of the base indicator. A six-page supplementary analysis and brief storymap give a cursory description of the EJ results.\nIndividual indicators can be explored as shown in Figure 7.2 visualization of SoCal cardiovascular disease percentiles.\n\n\n\n\n\n\nFigure 7.2: CalEnviroScreen Cardiovascular Disease\n\n\n\n\n\n7.3.2 EPA’s EJScreen\n\n\n\n\n\n\nFigure 7.3: EJSCREEN Ozone Indicator\n\n\n\nFigure 7.3 shows the EPA’s EJScreen index for ozone in SoCal. The U.S. Environmental Protection Agency’s EJScreen tool is also made up of two categories of data indicators, as documented in the 115-page technical report. EPA documentation states that EJScreen is a ’pre-decisional screening tool, and was not meant to be the basis for agency decision-making or determinations regarding the existence or absence of EJ concerns. It should also not be used to identify or label an area as an “EJ community.”\n\nEnvironmental Indicators - negative environmental indicators (i.e., air pollution, traffic, lead paint, proximity to hazardous waste sites, and wastewater discharge)\nDemographic Indicators - an average of the percentage of minority (i.e., non-white non-hispanic) and percentage of low-income households (2x poverty level).\n\nThe individual environmental indicators are combined with a demographic index value to provide individual EJ index values by environmental issue. Thus, there are 12 separate EJ indices provided in EJScreen.\n\n\n7.3.3 CDC and ATSDR Environmental Justice Index\n\n\n\n\n\n\nFigure 7.4: EJI for SoCal\n\n\n\nFigure 7.4 shows the Environmental Justice Index quartiles for SoCal. The Centers for Disease Control CDC Agency for Toxic Substances and Disease Registry ATSDR is a public health agency that has created its own indicator, which is documented in a 94 page technical report\nThe EJI uses three broad categories of indicators.\n\nSocial Vulnerability - Subgroups in this category include racial/ethnic minority status, socioeconomic categories, household demographics, and housing type\nEnvironmental Burden - Subgroups in this category include air pollution, hazardous and toxic sites, built environment, transportation corridors, and water pollution\nHealth Vulnerablity - This category includes five pre-existing chronic diseases, including asthma, cancer, blood pressure, diabetes, and mental health.\n\nThe three indicator categories are each weighted equally and averaged to generate a final single indicator value for the EJI. Each individual category is also available via mouseover or click on specific map locations.\n\n\n7.3.4 Climate and Economic Justice Screening Tool\n\n\n\n\n\n\nFigure 7.5: Climate and Environmental Justice Screening Tool\n\n\n\nFigure 7.5 shows the CEJST base visualization for environmental justice. The CEJST is from the President’s Council on Environmental Quality. The tool is intended to help identify disadvantaged communities that will benefit from programs included in the Justice40 initiative, which seeks to deliver 40% of overall benefits in climate, clean energy, and related areas to disadvantaged communities.\nCEJST uses a two-fold methodology somewhat similar to that followed in EJScreen. The tool uses multiple datasets as indicators of burden. A community is highlighted as disadvantaged on the CEJST map if it is at or above the…\n\nBurden threshold (climate change, energy, legacy pollution, health, housing, transportation, water, and workforce development)\nEconomic threshold (below 35th percentile income usually, low educational attainment for workforce development)\nIn a census tract completely surrounded by disadvantaged communities and at or above the low income median percentile.\n\n\n\n7.3.5 Discussion 2\n\nVisualization - What are your first thoughts about the visualization choices made by creators of these EJ tools? What do you like and dislike; what would you change?\nIndicators - Compare the sets of indicators in these tools. Are they measuring Environmental Justice? What EJ concepts are not covered by these indicators?\nGroupthink - Gather round in groups of 4 and pick a data layer to explore and compare in each of these tools. Once your group has decided, that layer cannot be picked by another group. Come up with a brief group story about your EJ data layer. In your story, tell the class which tool is best and why for illustrating your story. Similarly, tell the class which tool is worst and why for illustrating your story.",
    "crumbs": [
      "Home",
      "Unit 2: Environmental Justice",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>EJ - Screening Tools</span>"
    ]
  },
  {
    "objectID": "EJcategories.html",
    "href": "EJcategories.html",
    "title": "8  EJ - Praxis and Visualization",
    "section": "",
    "text": "8.1 Data Categories in EJ Tools\nAs discussed, in the previous lesson, there are a few broad categories of data that are currently used in Environmental Justice (EJ) tools. Let’s recap them here.\nAs we noted in the last class, these visualizations are more about identifying or screening for locations experiencing environmental injustice than about achieving or visualizing Environmental Justice.",
    "crumbs": [
      "Home",
      "Unit 2: Environmental Justice",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>EJ - Praxis and Visualization</span>"
    ]
  },
  {
    "objectID": "EJcategories.html#data-categories-in-ej-tools",
    "href": "EJcategories.html#data-categories-in-ej-tools",
    "title": "8  EJ - Praxis and Visualization",
    "section": "",
    "text": "Pollution Burden - negative environmental indicators of either pollution exposure, built environment, or environmental effects (e.g., ozone, PM, traffic, drinking water contaminants, toxic release facilities)\n\nSocioeconomic indicators - demographic and economic indicators of population\n\nHealth vulnerability - an indicator of population level health-effect data such as asthma, cancer, diabetes, cardiovascular, and low birth-weight\n\n\n\n8.1.1 Discussion 1\n\nWhat data is needed to understand the fair treatment principle of Environmental Justice?\nWhat data is needed to understand the meaningful involvement principle of Environmental Justice?\nHow does data availability limit our understanding and ability to visualize Environmental Justice?",
    "crumbs": [
      "Home",
      "Unit 2: Environmental Justice",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>EJ - Praxis and Visualization</span>"
    ]
  },
  {
    "objectID": "EJcategories.html#not-data---not-available",
    "href": "EJcategories.html#not-data---not-available",
    "title": "8  EJ - Praxis and Visualization",
    "section": "\n8.2 Not Data - Not Available",
    "text": "8.2 Not Data - Not Available\nMeaningful involvement is a very nebulous and hard-to-measure concept. Within the context of EJ, it indicates public participation with stakeholders and the influence to shape decision-making.\nThe EPA has a resource on public participation in decision-making.\n\n\n\n\n\n\nPublic participation is a process, not a single event. It consists of a series of activities and actions by a sponsor agency over the full lifespan of a project to both inform the public and obtain input from them. Public participation affords stakeholders (those that have an interest or stake in an issue, such as individuals, interest groups, communities) the opportunity to influence decisions that affect their lives.\n\n\n\nA large part of that framework is based on a schematic as shown in Figure 8.1 of the different possible levels of involvement by stakeholders in decision-making. The schematic is from the International Association of Public Participation.\n\n\n\n\n\nFigure 8.1: Public Participation Spectrum\n\n\nQuantifying meaningful involvement in a public participation process of decision-making is complicated and difficult to track. It is also a subjective judgement, although one could have systematic criteria for evaluating it. Moreover, the issue is probably better described as one in which the involvement levels are unequal between different stakeholder groups. In other words, developers and industry stakeholders are provided greater opportunity to shape policy and decision-making compared to residential and environmental stakeholders.\n\n8.2.1 Discussion 2.\n\nHow does a lack of data shape our ability to communicate and visualize an issue?\nHow could one collect information to visualize meaningful involvement?",
    "crumbs": [
      "Home",
      "Unit 2: Environmental Justice",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>EJ - Praxis and Visualization</span>"
    ]
  },
  {
    "objectID": "EJcategories.html#case-study---socal-warehouses---march-jpa-west-campus-upper-plateau",
    "href": "EJcategories.html#case-study---socal-warehouses---march-jpa-west-campus-upper-plateau",
    "title": "8  EJ - Praxis and Visualization",
    "section": "\n8.3 Case Study - SoCal Warehouses - March JPA West Campus Upper Plateau",
    "text": "8.3 Case Study - SoCal Warehouses - March JPA West Campus Upper Plateau\nI have been doing work with the Redford Conservancy on warehouses in the Inland Empire. As part of that work, I have developed a few mapping tools to visualize warehouse information.\nThe primary tool is called WarehouseCITY. WarehouseCITY is intended to provide a means for the public to easily access the impact of existing warehouses on their community. The code repository is located on github.\nA secondary tool provides a visualization of the existing and planned warehouse growth along the 215/60 freeways around the March Air Reserve Base in Riverside County (my backyard). That project’s draft Environmental Impact Report (EIR) is here\n\n8.3.1 Is Visualization Effective in Social Praxis?\nSometimes.\nYes, it works to get media attention and makes very convincing storytelling to those who already agree with you. It can change or engage people who are already on your side. It can surprise and influence people who are in the middle.\nNo, it does not seem to be very effective at engaging decision-makers directly. My experience has been that they are more interested in people and stories. In private meetings, they ooh and aah at the visualization but are more interested in strategy and coalition building - on the ground organization and political influence.\n\n8.3.2 Warehouse Visualization is Easy\n\n8.3.2.1 Load libraries\n\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(leaflet)\n\n\n8.3.2.2 Acquire data\nWe will also pull warehouse data for the first time! New data incoming!\nAlso note that I made this dataset smaller by using the filter() function to only include data from Riverside County; this removes about 7,500 warehouses from LA and San Bernardino counties.\n\nWH.url &lt;- 'https://raw.githubusercontent.com/RadicalResearchLLC/WarehouseMap/main/WarehouseCITY/geoJSON/comboFinal.geojson'\nwarehouses &lt;- st_read(WH.url) |&gt;  \n  filter(county == 'Riverside') |&gt;  \n  st_transform(\"+proj=longlat +ellps=WGS84 +datum=WGS84\")\n\nReading layer `comboFinal' from data source \n  `https://raw.githubusercontent.com/RadicalResearchLLC/WarehouseMap/main/WarehouseCITY/geoJSON/comboFinal.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 9106 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -118.8037 ymin: 33.43325 xmax: -114.4085 ymax: 35.55527\nGeodetic CRS:  WGS 84\n\n\nCheck to see what the warehouses dataset looks like.\n\nhead(warehouses)\n\nSimple feature collection with 0 features and 8 fields\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nGeodetic CRS:  +proj=longlat +ellps=WGS84 +datum=WGS84\n[1] apn        shape_area category   year_built class      county     unknown   \n[8] place_name geometry  \n&lt;0 rows&gt; (or 0-length row.names)\n\n\n\n8.3.2.3 Basic Visualization\nThis is geospatial data, so we should put it in an interactive leaflet map to do an initial visualization. Figure 8.2 shows a very basic polygon leaflet map.\n\nleaflet() %&gt;% \n  addTiles() %&gt;% \n  addPolygons(data = warehouses)\n\n\n\n\n\n\nFigure 8.2: Basic leaflet warehouse map\n\n\n\n\n8.3.2.4 Improve the Visualization\nThe setView() function allows us to set the zoom level and the centerpoint of the map using the arguments lng, lat, and zoom.\nWithin the addPolygons() function, I set the color to brown and the weight of the line to 1.\nFigure 8.3 shows the result for my neighborhood in Riverside.\n\nleaflet() %&gt;% \n  addTiles() %&gt;% \n  addPolygons(data = warehouses,\n              color = 'brown',\n              weight = 1) %&gt;% \n  setView(lng = -117.24, lat = 33.875, zoom = 12) #%&gt;% \n\n\n\n\n\n\nFigure 8.3: Leaflet warehouse map making warehouses brown\n\n\n\nLet’s add two more helpful things to orient viewers at a glance.\n\nLet’s change the underlying tile to satellite/aerial imagery using addProviderTiles()\n\nLet’s add a mini-map to orient the viewer to where this is using addMiniMap().\n\nFigure 8.4 shows the resulting map - note I added a palette to distinguish between existing warehouses (orange) and planned and approved warehouses (red) because brown has low salience in satellite imagery of SoCal.\n\npalWHtype &lt;- colorFactor(palette = c('darkorange', 'red'),\n                         domain = warehouses$category)\n\nleaflet() %&gt;% \n  addTiles() %&gt;% \n  addPolygons(data = warehouses,\n              color = ~palWHtype(category),\n              weight = 1) %&gt;% \n  setView(lng = -117.24, lat = 33.875, zoom = 12) %&gt;% \n  addProviderTiles(provider = providers$Esri.WorldImagery) %&gt;% \n  addMiniMap(position = 'bottomleft')\n\n\n\n\n\n\nFigure 8.4: Leaflet warehouse map near March JPA",
    "crumbs": [
      "Home",
      "Unit 2: Environmental Justice",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>EJ - Praxis and Visualization</span>"
    ]
  },
  {
    "objectID": "EJdata.html",
    "href": "EJdata.html",
    "title": "9  EJ - Exploratory Analysis Case Study",
    "section": "",
    "text": "9.1 Load and Import Steps\nLoad the libraries we’ll be using today.\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(leaflet)\nImport the SoCalEJ dataset again, if you don’t have it already loaded.\nURL.path &lt;- 'https://raw.githubusercontent.com/RadicalResearchLLC/EDVcourse/main/CalEJ4/CalEJ.geoJSON'\nSoCalEJ &lt;- st_read(URL.path) |&gt;  \n  st_transform(\"+proj=longlat +ellps=WGS84 +datum=WGS84\")",
    "crumbs": [
      "Home",
      "Unit 2: Environmental Justice",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>EJ - Exploratory Analysis Case Study</span>"
    ]
  },
  {
    "objectID": "EJdata.html#basic-visualization",
    "href": "EJdata.html#basic-visualization",
    "title": "9  EJ - Exploratory Analysis Case Study",
    "section": "\n9.2 Basic Visualization",
    "text": "9.2 Basic Visualization\nLet’s compare some variables by county to see how the counties are different.\nPick your own variable to plot - do not pick OzoneP which is my variable for now.\nUse filter(...) to only keep values above or equal to zero. We don’t want to include census tracts that are missing data that have -999 values.\nFigure 9.2 shows the distribution of ozone exposure percentages by county.\n\nSoCalEJ |&gt;  \n  filter(OzoneP &gt;= 0) |&gt;  \n  ggplot(aes(x = County, y = OzoneP)) +\n  geom_boxplot()\n\n\n\n\n\n\nFigure 9.2: Ozone census tract distribution by county\n\n\n\n\nThere are clear differences in ozone by county, with the Inland counties having higher ozone than the coastal counties. The differences are statistically significant.\nUnfortunately, a wide dataset is not great at displaying multivariate information in ggplot. A bit of tidying is needed to display multiple variables.",
    "crumbs": [
      "Home",
      "Unit 2: Environmental Justice",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>EJ - Exploratory Analysis Case Study</span>"
    ]
  },
  {
    "objectID": "EJdata.html#tidy-and-transform",
    "href": "EJdata.html#tidy-and-transform",
    "title": "9  EJ - Exploratory Analysis Case Study",
    "section": "\n9.3 Tidy and Transform",
    "text": "9.3 Tidy and Transform\nI am going to demonstrate a few somewhat fancy data manipulation techniques. This is somewhat advanced database programming. While this is very helpful for visualization, it goes beyond the things I expect you to learn for this course.\nThis code does three things.\n\nRemove the geometry using st_set_geometry(value = NULL)\n\nTransform the data table from wide to long using pivot_longer(...)\n\nRemove values below zero using filter()\n\n\n\n# select socioeconomic indicators and make them narrow - only include counties above 70%\nSoCal_narrow &lt;- SoCalEJ |&gt;  \n  st_set_geometry(value = NULL) |&gt;  \n  pivot_longer(cols = c(5:66), names_to = 'variable', values_to = 'value') |&gt;  \n  filter(value &gt;=0)\n\nLet’s compare the SoCalEJ and SoCal_narrow datasets using head().\n\nhead(SoCalEJ)\n\nSimple feature collection with 6 features and 66 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -117.874 ymin: 33.5556 xmax: -117.7157 ymax: 33.64253\nGeodetic CRS:  +proj=longlat +ellps=WGS84 +datum=WGS84\n       Tract   ZIP County     ApproxLoc TotPop19   CIscore   CIscoreP\n1 6059062640 92656 Orange   Aliso Viejo     3741  9.642007 12.1028744\n2 6059062641 92637 Orange   Aliso Viejo     5376 10.569290 14.3343419\n3 6059062642 92625 Orange Newport Beach     2834  3.038871  0.6807867\n4 6059062643 92657 Orange Newport Beach     7231  6.538151  5.8497226\n5 6059062644 92660 Orange Newport Beach     8487  8.873604 10.4009077\n6 6059062645 92657 Orange Newport Beach     6527  6.033648  4.7402925\n       Ozone   OzoneP     PM2_5  PM2_5_P   DieselPM DieselPM_P  Pesticide\n1 0.05165298 65.36403  9.445785 43.88301 0.14536744   50.13068 0.00000000\n2 0.05219839 66.80772  9.785209 46.89484 0.07372588   27.41755 0.00000000\n3 0.04827750 55.38270 10.433417 52.03485 0.03478566   12.40821 0.06496406\n4 0.04901945 58.23273 10.013395 49.29683 0.03594981   12.90604 0.00000000\n5 0.04863521 56.96329 10.565404 52.63223 0.07701293   28.73678 0.00000000\n6 0.04863521 56.96329 10.329985 51.28811 0.04047264   14.58619 0.00000000\n  PesticideP   Tox_Rel Tox_Rel_P   Traffic TrafficP DrinkWat DrinkWatP\n1    0.00000  293.8420  41.44786  999.0182  57.7125 177.3831  5.907331\n2    0.00000  681.0703  57.65191 1051.9778  61.2250 312.7169 25.939803\n3   22.58621 1557.6400  74.05601  874.8193  49.5000 332.6654 32.284251\n4    0.00000 1349.2300  70.69267 1169.7532  67.4250 332.6654 32.284251\n5    0.00000 1889.5133  78.03201 1383.9867  74.9500 332.6654 32.284251\n6    0.00000 1589.1400  74.44361 1025.2790  59.5750 332.6654 32.284251\n       Lead    Lead_P Cleanup  CleanupP GWThreat GWThreatP HazWaste HazWasteP\n1 18.450498 10.737240     0.0  0.000000      0.0  0.000000    0.280  46.80344\n2  9.898042  3.730309     0.0  0.000000      0.0  0.000000    0.280  46.80344\n3 14.263664  6.830498     4.5 40.836133      2.0 14.311805    0.150  26.67108\n4  5.594984  1.600504     0.0  0.000000      0.5  2.722896    0.210  37.68365\n5 16.777373  9.061122     0.0  0.000000      7.5 39.448780    0.395  60.22502\n6 12.086059  5.343415     0.7  9.593132      2.0 14.311805    0.100  16.63799\n  ImpWatBod ImpWatBodP SolWaste SolWasteP PollBurd PolBurdSc PolBurdP Asthma\n1         7   66.73667        0   0.00000 30.50123  3.724194 18.95457  21.70\n2         7   66.73667        2  52.89805 35.23480  4.302163 29.71998  21.74\n3         8   72.15456        0   0.00000 35.68847  4.357555 30.77785  14.93\n4         6   58.69383        0   0.00000 30.97653  3.782228 19.87554  10.33\n5         2   23.87652        2  52.89805 39.48486  4.821094 41.44368  13.88\n6         3   33.15834        2  52.89805 32.98028  4.026885 24.04480  10.51\n     AsthmaP LowBirtWt   LowBirWP Cardiovas CardiovasP Educatn     EducatP\n1 11.2786640      4.45 37.2337696      9.74 27.5049850     1.0    1.771703\n2 11.3908275      3.50 16.2176033      8.72 18.8310070     8.4   35.876993\n3  3.7263210      1.18  0.2950988      5.41  1.8569292  -999.0 -999.000000\n4  0.9845464      5.39 61.9450860      4.46  0.3988036     2.0    5.859276\n5  2.7542373      2.86  7.6597383      5.43  1.9192423     3.7   14.781068\n6  1.0343968      4.64 42.1991275      4.65  0.4860419     0.0    0.000000\n  Ling_Isol Ling_IsolP Poverty  PovertyP Unempl     UnemplP HousBurd HousBurdP\n1       1.1   7.375829    20.0 34.208543    3.0   17.113483     19.9 62.420786\n2       4.4  33.942347    12.9 16.821608    2.6   11.868818     19.5 60.925222\n3       0.0   0.000000     9.5  8.982412    0.9    1.145237     14.5 35.817490\n4       3.9  30.694275     6.9  4.170854    2.6   11.868818      8.5  8.504436\n5       5.0  37.664095    12.3 15.326633    4.0   30.882353     18.9 58.225602\n6       1.0   6.266071    11.5 13.517588 -999.0 -999.000000     14.8 37.477820\n    PopChar PopCharSc   PopCharP Child_10 Pop_10_64 Elderly65 Hispanic   White\n1 24.958604 2.5890185 13.2375189  10.9864   81.7696    7.2441  16.4662 63.2184\n2 23.683405 2.4567389 11.7750882  13.2812   61.9792   24.7396  22.0238 55.2455\n3  6.722867 0.6973798  0.2647504   5.9280   49.6471   44.4248   5.6104 89.6260\n4 16.664505 1.7286508  4.9167927   7.9657   67.7361   24.2982   4.4530 63.9331\n5 17.743511 1.8405788  5.8119012  10.4866   72.3224   17.1910   8.8488 82.0785\n6 14.444279 1.4983412  3.3787191  11.0311   68.4388   20.5301   3.8302 74.7664\n  AfricanAm NativeAm OtherMult Shape_Leng Shape_Area    AAPI\n1    4.9452   0.0000    3.6087   5604.596    1467574 11.7616\n2    1.3765   0.0000    3.5900   6244.598    2143255 17.7641\n3    0.3881   0.0000    1.4467   6803.947    2048571  2.9287\n4    0.0000   0.3042    6.0987  26448.643   18729420 25.2109\n5    0.0000   0.0000    1.1076  10964.108    4361037  7.9651\n6    0.2911   0.0000    0.8733   9833.066    5754643 20.2390\n                        geometry\n1 MULTIPOLYGON (((-117.7178 3...\n2 MULTIPOLYGON (((-117.7166 3...\n3 MULTIPOLYGON (((-117.8596 3...\n4 MULTIPOLYGON (((-117.7986 3...\n5 MULTIPOLYGON (((-117.8521 3...\n6 MULTIPOLYGON (((-117.8269 3...\n\nhead(SoCal_narrow)\n\n# A tibble: 6 × 6\n       Tract   ZIP County ApproxLoc   variable     value\n       &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;       &lt;chr&gt;        &lt;dbl&gt;\n1 6059062640 92656 Orange Aliso Viejo TotPop19 3741     \n2 6059062640 92656 Orange Aliso Viejo CIscore     9.64  \n3 6059062640 92656 Orange Aliso Viejo CIscoreP   12.1   \n4 6059062640 92656 Orange Aliso Viejo Ozone       0.0517\n5 6059062640 92656 Orange Aliso Viejo OzoneP     65.4   \n6 6059062640 92656 Orange Aliso Viejo PM2_5       9.45  \n\n\nThe SoCal_narrow dataset has taken the 60+ columns from SoCalEJ and condensed them into a single column indicating the variable and another column indicating the value for that variable. This is very useful for grouping and visualizing by category of information.\nNow let’s display a box plot with three pollution variables simultaneously using this narrow dataset as shown in Figure 9.3. We again use filter(), but we combine it with the %in% operator to select multiple variables to display.\n\nSoCal_narrow |&gt;  \n  filter(variable %in% c('OzoneP', 'DieselPM_P', 'PolBurdP')) |&gt;  \n  ggplot(aes(x = County, y = value, fill= variable)) +\n  geom_boxplot()\n\n\n\n\n\n\nFigure 9.3: Comparison of ozone, diesel PM, and Pollution burden by county\n\n\n\n\nCool! Now we are seeing some interesting differences.\n\n9.3.1 Exercise 1.\n\nCreate a boxplot that displays five simultaneous variables by County, either by adding two new variables and/or replacing the existing variables. I recommend showing the percentage values that end in P.\nChoose a different theme()\n\nShow a box plot of the six racial and ethnic variables - Hispanic, White, AfricanAm, NativeAm, OtherMult, and AAPI. It should look something like Figure 9.4\n\n\n\n\n\n\n\n\n\nFigure 9.4: Comparison of racial and ethnic population distributions by county\n\n\n\n\n\n9.3.2 Explore the Dataset\nData visualization isn’t just a final product. To get to the final product usually requires doing significant visual exploration to reveal information and knowledge.\nLet’s walk through a few examples of methods to explore the data.\n\n9.3.2.1 Scatter plots\nIs there a relationship between a dependent and an independent variable or 3? Scatter plots and fits help to examine that.\nFigure 9.5 investigates poverty as an independent variable with the pollution burden indicator by county.\n\nSoCalEJ  |&gt;  \n  filter(PovertyP &gt;= 0) |&gt;  \n  ggplot(aes(x = PovertyP, y = PolBurdP, color = County)) +\n  geom_point(size = 0.5, alpha = 0.5) +\n  geom_smooth() +\n  theme_bw() +\n  facet_wrap(~County)\n\n\n\n\n\n\nFigure 9.5: Relationship of poverty and pollution burden by county\n\n\n\n\nVery interesting dataset here. Poverty percentage in a census tract increases pollution burden in Orange, LA, and Riverside County but has no impact in San Bernardino. Riverside is the least pollution burdened on average, while both LA and Orange County have the highest pollution burden.\nLet’s look at one other scatter plot of estimated pollution burden and a health outcome.\n\nSoCalEJ |&gt;  \n  filter(PolBurdP &gt;= 0 & CardiovasP &gt;= 0) |&gt;  \n  ggplot(aes(x = PolBurdP, y = CardiovasP, color = County)) +\n  geom_point(size = 0.5, alpha = 0.5) +\n  geom_smooth() +\n  theme_bw() +\n  facet_wrap(~County)\n\n\n\n\n\n\nFigure 9.6: Relationship of pollution burden and cardiovascular disease by county\n\n\n\n\nVery strange here. Orange County has a positive relationship, but the other counties have non-linear relationships between these two variables.\n\n9.3.2.2 Exercise 2.\n\nGenerate a hypothesis of a causal relationship that you can test. Does variable X cause variable Y to increase/decrease?\nPrepare a four-county scatter-plot of your selected variables you think may have a causal relationship.\nExamine the results. Is there a relationship? Does it vary by county?\n\n9.3.2.3 Histograms\nHistograms are useful ways to explore a distribution of values.\nThe basic histogram is shown in Figure 9.7. The distribution of high pollution burden census tracts is skewed right towards higher values (i.e., worst scores).\n\nSoCalEJ |&gt;  \n  filter(PolBurdP &gt;= 0)  |&gt;  \n  ggplot(aes(x = PolBurdP)) +\n  geom_histogram() #+\n  #theme_bw() +\n  #facet_wrap(~County)\n\n\n\n\n\n\nFigure 9.7: Distribution of pollution burden scores by census tract\n\n\n\n\nNow let’s make that prettier and add a facet_wrap() by county as shown in Figure 9.8. I’ll also fix the axis labels using the labs() function to name them real names.\n\nSoCalEJ |&gt;  \n  filter(PolBurdP &gt;= 0)  |&gt;  \n  ggplot(aes(x = PolBurdP, fill = County)) +\n  geom_histogram() +\n  theme_bw() +\n  facet_wrap(~County) +\n  labs(x = 'Pollution Burden (%)', \n       y = 'Count of census tracts')\n\n\n\n\n\n\nFigure 9.8: Distribution of pollution burden scores by census tract and county\n\n\n\n\nNow, we can clearly see very big differences in census tract counts and distributions of the pollution burden variable. LA County has a massive distribution of highly burdened census tracts.\n\n9.3.2.4 Exercise 3.\n\nChoose a variable you think is interesting and make a four-county histogram plot of it.\nIs there a story that you can start to craft with your histogram?\n\n9.3.3 Bar and Column plots (column is usually better)\nBasic example of a bar plot is shown in Figure 9.9.\n\nSoCalEJ |&gt;  \n  filter(PolBurdP &gt;= 0)  |&gt;  \n  ggplot(aes(x = County)) +\n  geom_bar() \n\n\n\n\n\n\nFigure 9.9: Basic bar plot\n\n\n\n\nThere are more census tracts in LA than the other counties, because far more people live in LA than the other counties.\nWe can try to put the places in there, but it gets messy as shown in fig-Bar2 when looking at San Bernardino places. I’ve switched them to the y-axis to make it horizontal and made the font text smaller using\n\nSoCalEJ |&gt;  \n  filter(County == 'San Bernardino') |&gt;  \n  ggplot(aes(y = ApproxLoc)) +\n  geom_bar() +\n  theme(axis.text = element_text(size = 6)) +\n  labs(y = '', x = 'Count of census tracts')\n\n\n\n\n\n\nFigure 9.10: Basic bar plot\n\n\n\n\nNote that geom_bar() works well with categorical variables, but doesn’t like continuous and numerical values.\n\n9.3.4 Exploration and Improvisation\nIn this section, we are going to follow your interests to generate visualizations improvisationally. Hopefully there will be minimal struggle.\n\n9.3.4.1 Noodle Zone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSoCalEJ |&gt;  \n  filter(County == 'San Bernardino') |&gt;  \n  ggplot(aes(y = ApproxLoc)) +\n  geom_bar() +\n  theme(axis.text = element_text(size = 6)) +\n  labs(y = '', x = 'Count of census tracts')",
    "crumbs": [
      "Home",
      "Unit 2: Environmental Justice",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>EJ - Exploratory Analysis Case Study</span>"
    ]
  },
  {
    "objectID": "EJPolygons.html",
    "href": "EJPolygons.html",
    "title": "10  EJ - Drawing Polygons for Warehouse CENTRAL",
    "section": "",
    "text": "10.1 Project Example\nPLACEHOLDER - we’ll use a different example.",
    "crumbs": [
      "Home",
      "Unit 2: Environmental Justice",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>EJ - Drawing Polygons for Warehouse CENTRAL</span>"
    ]
  },
  {
    "objectID": "EJPolygons.html#project-example",
    "href": "EJPolygons.html#project-example",
    "title": "10  EJ - Drawing Polygons for Warehouse CENTRAL",
    "section": "",
    "text": "Figure 10.1: Airport Gateway Land Use Plan",
    "crumbs": [
      "Home",
      "Unit 2: Environmental Justice",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>EJ - Drawing Polygons for Warehouse CENTRAL</span>"
    ]
  },
  {
    "objectID": "EJPolygons.html#cumulative-impacts",
    "href": "EJPolygons.html#cumulative-impacts",
    "title": "10  EJ - Drawing Polygons for Warehouse CENTRAL",
    "section": "\n10.2 Cumulative Impacts",
    "text": "10.2 Cumulative Impacts\nToday, I am going to ask you all to help with a cumulative impacts analysis (for the project. Under CEQA Section 15355, cumulative impacts are defined as ‘two or more individual effects, when considered together, are considerable or which compound or increase other environmental impacts…The cumulative impact from several projects is the change in the environment which results from the incremental impact of the project when added to other closely related past, present, and reasonably foreseeable future projects.’\nA cumulative impacts analysis identifies the past, present, and probable future projects that should be included in the EIR.\nThe Warehouse CITY tool is designed to do exactly this. In Spring 2023, my class and helped to add dozens of planned warehouses to the existing warehouses map. This work helped us to add a layer of ’planned and approved warehouses to the tool allowing users to see what warehouses are likely to be built in the near future.\nWithin 3.1 miles (5 km) of the Airport Gateway project, the tool indicates that there are already 1740+ acres of warehouses. Using the default warehouse floor-area-ratio assumption of 0.65, and a truck trip generation rate of 0.67 trucks per 1000 square feet of warehouses, this results in an estimate of over 30,000 truck trips daily from this region. ?fig-AGarea shows the output. You can alter the circle size or move the starting point and see how sensitive the estimate is to the default assumptions. Also, you can zoom in with aerial imagery and see that a few warehouses aren’t identified in this analysis.",
    "crumbs": [
      "Home",
      "Unit 2: Environmental Justice",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>EJ - Drawing Polygons for Warehouse CENTRAL</span>"
    ]
  },
  {
    "objectID": "EJPolygons.html#visualization---drawing-a-polygon",
    "href": "EJPolygons.html#visualization---drawing-a-polygon",
    "title": "10  EJ - Drawing Polygons for Warehouse CENTRAL",
    "section": "\n10.3 Visualization - Drawing a Polygon",
    "text": "10.3 Visualization - Drawing a Polygon\nNote, this is a highly manual approach. There better ways to do this systematically and I’ve developed a tool to start doing that called the Polygon Export Tool. If we were really smart, we could do machine learning to figure out how to do this, but I have not taken the time to build a tool to more fully automate this process.\nFirst, we always do the basics, then we’ll show the tool and how it can simplify the process - assuming you know where to find files on your machine.\n\n10.3.1 Load libraries\n\nlibrary(sf)\nlibrary(leaflet)\n\n\n10.3.2 Manually Identify the Polygon Vertices.\nOpen Google Maps or an equivalent mapping tool with satellite imagery and an ability to click on a location and retrieve a decimal degree location.\nFind a vertex on the map - input longitude and latitude into a list in the form c(lng, lat).\nDo that for all the vertex points and bind them together as a list of lists as shown in the code below.\n\nAirportGateway1 &lt;- rbind(\n                    c(-117.26095, 34.11023),\n                    c(-117.26095, 34.10611),\n                    c(-117.25946, 34.10484),\n                    c(-117.24921, 34.10484),\n                    c(-117.24455, 34.1069),\n                    c(-117.22594, 34.1069),\n                    c(-117.21669, 34.1069),\n                    c(-117.21262, 34.1069),\n                    c(-117.21248, 34.10476),\n                    c(-117.20905, 34.10528),\n                    c(-117.20532, 34.10613),\n                    c(-117.1997, 34.10617),\n                    c(-117.1998, 34.1116),\n                    c(-117.20086, 34.11073),\n                    c(-117.2117, 34.11074),\n                    c(-117.21757, 34.109),\n                    c(-117.21757, 34.11032),\n                    c(-117.24932, 34.11012),\n                    c(-117.24932, 34.10847),\n                    c(-117.25412, 34.10847),\n                    c(-117.25412, 34.11012),\n                    c(-117.26095, 34.11023)\n                    )\n\nLook at the AirportGateway table - it looks like a list of point coordinates.\nWe need one more bit of code to convert that into a polygon. It is a bit complicated.\n\nAirportGatewaySP &lt;- st_sf(\n                      name = 'Airport Gateway Specific Plan Area', \n                      geom = st_sfc(st_polygon(list(AirportGateway1))), \n                      crs = 4326\n                      )\n\nThe name is our label for the polygon, so that’s easy. The crs is the coordinate reference system, in this case WGS84 = 4326 for easy display in leaflet.\nThe geom is the geometry. Three functions are applied - list() which converts the AirportGateway1 table to a list, st_polygon() which returns a polygon from a list of coordinates, and st_sfc() which verifies the contents and sets its class.\n\n\n\n\n\n\nPolygons always have to start and end with the same vertex to be a closed loop.\n\n\n\nNow we should display it to make sure it looks correct. Figure 10.2 shows the attempt.\n\nleaflet()  |&gt;  \n  addTiles() |&gt; \n  addPolygons(data = AirportGatewaySP,\n              color = 'darkred',\n              fillOpacity = 0.6,\n              weight = 1)\n\n\n\n\n\n\nFigure 10.2: Airport Gateway polygon check\n\n\n\nThat looks pretty close.\nNow let’s add a warehouse layer showing all planned and approved warehouse projects within California that went through CEQA review from 2020-2024.\nFirst import the warehouse dataset. Let’s name this dataset plannedWH or something to make it unique.\n\nplannedWH.url &lt;- 'https://github.com/RadicalResearchLLC/CEQA_tracker/raw/main/CEQA_WH.geojson'\nplannedWH &lt;- st_read(plannedWH.url) |&gt; \n  st_transform(crs = 4326) # crs = coordinate reference system and 4326 is WGS84\n\nReading layer `CEQA_WH' from data source \n  `https://github.com/RadicalResearchLLC/CEQA_tracker/raw/main/CEQA_WH.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 482 features and 12 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -122.7967 ymin: 32.59353 xmax: -115.3887 ymax: 40.53671\nGeodetic CRS:  WGS 84\n\n\nNow let’s add the existing warehouses to the map. Let’s also use setView() to zoom in on our area of interest cause San Bernardino County is really big.\nFigure 10.3\n\nleaflet() |&gt; \n  addTiles() |&gt; \n  addProviderTiles(provider = providers$CartoDB.Positron) |&gt; \n  addPolygons(data = AirportGatewaySP,\n              color = 'darkred',\n              fillOpacity = 0.6,\n              weight = 1) |&gt; \n  addPolygons(data = plannedWH,\n              color = 'brown',\n              weight = 1) |&gt; \n  setView(lng = -117.34, lat = 34.10528, zoom = 11)\n\n\n\n\n\n\nFigure 10.3: Airport Gateway project in bigger context with less busy map.\n\n\n\n\n10.3.3 In-Class Exercise\nPlaceholder\n\n10.3.4 Planned Warehouses Map for the Central Valley\nWarehouse CENTRAL\nI want to add warehouses for every other part of the Central Valley.\nWe need to find land use and assessor parcel datasets for each of the counties and major cities in the Central Valley.\nWe have currently pulled in San Joaquin and Stanislaus Counties, and the cities of Tracy, Stockton, Lathrop, and Manteca.\nIn approximate order of importance, the counties that need to be targeted are Kern, Sacramento, Fresno, Madera, Tulare, Placer, and Yolo.\nKey cities to include are Sacramento, Fresno, Bakersfield, Modesto, Visalia, Merced, Woodland, West Sacramento,",
    "crumbs": [
      "Home",
      "Unit 2: Environmental Justice",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>EJ - Drawing Polygons for Warehouse CENTRAL</span>"
    ]
  },
  {
    "objectID": "assignment2.html",
    "href": "assignment2.html",
    "title": "11  Assignments for Unit 2 - EJ",
    "section": "",
    "text": "11.1 Graded Assignment - EJ Visualization\nChoose an environmental justice dataset. Three options we discuss in class are:\nIf data downloads are not something you are comfortable with, it is perfectly ok to use the in-class SoCalEJ dataset we have used as an example for in-class coding assignments.\nThe assignment is to create a new visualization or remix of a visualization using some of the data from the chosen EJ dataset. Visualization options include:\nPoints will be awarded for successfully generating a unique visualization, for having made four distinct visualization choices that are different from the standard tool, and for documenting those four unique features in the accompanying email, or as commented text within the .R script file you submit as part of the assignment. Note, the goal is to make an attractive figure, not a super ugly one. Choices that do not aid in improving the feature for the audience will not be considered on point. For example, making the font enormous or tiny is a negative feature.\nIn other words, the goal is to make a better visualization, not just a different visualization. When describing the four feature changes, describe in one sentence why the features improve the visualization.\nAssignment is currently due October 1st, 2024 at the beginning of class (9:45 AM). Please send the .R script and an exported visualization via email. This assignment is worth 150 points. Coding style will not be graded. Scripts will be used to reproduce the figure on my local machine - deviations between code and exported figure will likely result in deducted points.",
    "crumbs": [
      "Home",
      "Unit 2: Environmental Justice",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Assignments for Unit 2 - EJ</span>"
    ]
  },
  {
    "objectID": "assignment2.html#graded-assignment---ej-visualization",
    "href": "assignment2.html#graded-assignment---ej-visualization",
    "title": "11  Assignments for Unit 2 - EJ",
    "section": "",
    "text": "CalEnviroScreen - WARNING - 20+Mb zip file\n\nEPA EJScreen - WARNING - 480+ Mb zip file\n\nCDC & ATSRD EJI tool - state level downloads - pick geoJSON format for maps!\n\nCEJST WARNING - 357 Mb zip file\n\n\n\n\nLeaflet map(s)\nggplot geom_sf map(s)\nggplot figure(s) using some other geom (boxplot, point, bar, histogram)\nSome combination of 1, 2, and 3",
    "crumbs": [
      "Home",
      "Unit 2: Environmental Justice",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Assignments for Unit 2 - EJ</span>"
    ]
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Appendix A — Course Syllabus",
    "section": "",
    "text": "A.1 Course Description\nThis is an introductory course on the theory and practice of effective communication with quantitative data. This course will introduce the theory of data visualization, discuss the ethics of data visualization, provide hands-on training in acquiring, tidying, and visualizing quantitative environmental data, and critically examine current environmental justice tools (CalEnviroScreen, EPA’s EJScreen, CEJST).",
    "crumbs": [
      "Home",
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Course Syllabus</span>"
    ]
  },
  {
    "objectID": "syllabus.html#course-materials",
    "href": "syllabus.html#course-materials",
    "title": "Appendix A — Course Syllabus",
    "section": "\nA.2 Course Materials",
    "text": "A.2 Course Materials\nGo here to see all course materials.\nThe course materials are built using the quarto environment which is R Markdown adjacent, but allows a user to embed functional code in R, Python, Julia, and/or Observable JS.\nAll code used is on github\nAny readings assigned will be emailed to students and/or posted to Box for download. Box will be linked within the course materials for assignments.\n\n\n\n\n\n\nCourse layout and materials listed on course materials page are subject to change due to shifting conditions that occur during the course of the semester. I will update course materials on a weekly basis to reflect the changing conditions and expectations throughout the semester.",
    "crumbs": [
      "Home",
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Course Syllabus</span>"
    ]
  },
  {
    "objectID": "syllabus.html#course-goals-learning-objectives",
    "href": "syllabus.html#course-goals-learning-objectives",
    "title": "Appendix A — Course Syllabus",
    "section": "\nA.3 Course Goals & Learning Objectives",
    "text": "A.3 Course Goals & Learning Objectives\nUpon successful completion of this course, students will\n\nacquire critical thinking skills on the display of visual information\nimprove team-based collaboration abilities by working on group projects\nknow how to acquire, tidy, and summarize quantitative environmental datasets\ncreate graphs and maps in R\n\ncritically review current environmental justice tools such as CalEnviroScreen and EJScreen\n\nunderstand basic theory and ethics of environmental data visualization",
    "crumbs": [
      "Home",
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Course Syllabus</span>"
    ]
  },
  {
    "objectID": "syllabus.html#student-learning-outcomes",
    "href": "syllabus.html#student-learning-outcomes",
    "title": "Appendix A — Course Syllabus",
    "section": "\nA.4 Student Learning Outcomes",
    "text": "A.4 Student Learning Outcomes\n\nCritical Thinking, Quantitative Reasoning, and Effective Expression - Upon completion of this course, student’s will be able to critically examine the elements of environmental data visualization, create effective maps and graphs of environmental data, and effectively communicate environmental ideas in a quantitative visual manner. It will also focus on the theory and ethics of data visualization with readings and critical analysis of existing environmental justice tools.\nSocial Justice Theory - This course will identify and quantitatively explore the unequal distribution and access to natural resources (Environmental Justice) within California and the United States. Students will critically examine the ways Environmental Justice is currently characterized by government agencies and describe the types of data visualization used to quantitatively identify areas of disproportional impact and understand the limitations of existing tools in promoting effective change.",
    "crumbs": [
      "Home",
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Course Syllabus</span>"
    ]
  },
  {
    "objectID": "syllabus.html#classroom-approach",
    "href": "syllabus.html#classroom-approach",
    "title": "Appendix A — Course Syllabus",
    "section": "\nA.5 Classroom Approach",
    "text": "A.5 Classroom Approach\nIn-person class time will include approximately 30% of time to devoted to lectures, 40% to hands-on coding and data visualization, and 30% to discussion.",
    "crumbs": [
      "Home",
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Course Syllabus</span>"
    ]
  },
  {
    "objectID": "syllabus.html#assignments-and-activities",
    "href": "syllabus.html#assignments-and-activities",
    "title": "Appendix A — Course Syllabus",
    "section": "\nA.6 Assignments and Activities",
    "text": "A.6 Assignments and Activities\n\nClassroom participation during discussion sections\nClassroom participation during coding sessions\nAssigned reading (news and peer-review articles, online books)\nAssigned review of web tools (CalEnviroScreen, EJScreen, CEJST)\nGroup coding projects\nClass presentation on an environmental data visualization\nIndividual projects generating, displaying, or critiquing environmental data visualizations\nGroup project creating an environmental data visualization",
    "crumbs": [
      "Home",
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Course Syllabus</span>"
    ]
  },
  {
    "objectID": "syllabus.html#grading-and-assessment-breakdown",
    "href": "syllabus.html#grading-and-assessment-breakdown",
    "title": "Appendix A — Course Syllabus",
    "section": "\nA.7 Grading and Assessment Breakdown",
    "text": "A.7 Grading and Assessment Breakdown\nThe class will be based on a total of 1000 points.\n\nThe three individual projects displaying or reviewing environmental data will count for 150 or 200 points (500 in total).\nA written and presnted critique of an existing environmental data visualization\nRemix of an environmental justice dataset from an existing EJ tool\nA student proposed and executed environmental data visualization (map, figure, infographic, interactive tool)\nThe group project displaying environmental data visualization will count for 250 points\nA group presentation on environmental data visualization in Environmental Justice tools will count for 150 points\nClassroom participation will count for 150 points throughout the course of the semester. These points will be awarded for attendance and active participation in classroom discussion and coding sessions. Online attendance and participation will count towards this activity in case of sickness or inability to attend in-person.\nMissing classroom discussion and coding sessions can be made up for 80% credit within two weeks or 50% credit within four weeks by attending online or in-person office hours.\nExtra credit - Identifying errors in course lectures, asking questions of guest speakers, and bringing snacks to enhance class morale can earn extra credit in 10 point chunks.\n\nStudents get a single free individual or group project that can be late by up to seven days from the due date. For the group project, if a member of the group has already used their individual free late project, the group cannot use other individual free periods. If any other project is late, scores will be reduced by 10% per day beyond the due date of the project.\nThe assigned presentation date requires a doctor’s note for an excused absence. If unexcused, the student can make up the presentation or final exam for 75% credit within one week of the assigned date.\nThis course will be attempting to engage in ungrading to give scholars more control over their own review of their progress and success in the class. The goal is for internal motivation and ownership of the definition of classroom success. In practice, ungrading is essentially an agreement to allow students to redo and resubmit assignments up until the last day of class. This requires students to communicate in writing that the intent is to resubmit an assignment within 10 days of receiving the initial grade. Late assignment penalties will still apply.\nTable A.1\n\n\n\nTable A.1: Breakdown of course points\n\n\n\n\n\n\n\n\nAssignments\nPoints\n\n\n\nGroup Project - data visualization\n250\n\n\nIndividual project 1 - written critique of existing visualization\n150\n\n\nIndividual Project 2 - - EJ tool remix\n150\n\n\nIndividual Project 3 - data visualization\n200\n\n\nGroup Presentation on EJ tools\n150\n\n\nClassroom participation\n100\n\n\nExtra Credit\n50",
    "crumbs": [
      "Home",
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Course Syllabus</span>"
    ]
  },
  {
    "objectID": "syllabus.html#office-hours",
    "href": "syllabus.html#office-hours",
    "title": "Appendix A — Course Syllabus",
    "section": "\nA.8 Office Hours",
    "text": "A.8 Office Hours\n\nMonday 2:00 - 3:00 zoom\n\nTuesdays 9:00 - 9:30 (before class) - in classroom?\nThursday at 9:00 - 9:30 (before class) - in classroom?\nFriday 9:00 - 10:00 zoom",
    "crumbs": [
      "Home",
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Course Syllabus</span>"
    ]
  },
  {
    "objectID": "syllabus.html#contact-info",
    "href": "syllabus.html#contact-info",
    "title": "Appendix A — Course Syllabus",
    "section": "\nA.9 Contact Info",
    "text": "A.9 Contact Info\nThe best way to get a hold of me is email: michael_mccarthy@pitzer.edu You are also likely to see emails from my non-pitzer email: mikem@radicalresearch.llc",
    "crumbs": [
      "Home",
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Course Syllabus</span>"
    ]
  },
  {
    "objectID": "syllabus.html#course-materials-1",
    "href": "syllabus.html#course-materials-1",
    "title": "Appendix A — Course Syllabus",
    "section": "\nA.10 Course materials",
    "text": "A.10 Course materials\nAll course materials will be hosted on github.\nGo here to see all course materials.",
    "crumbs": [
      "Home",
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Course Syllabus</span>"
    ]
  },
  {
    "objectID": "syllabus.html#covid-policy",
    "href": "syllabus.html#covid-policy",
    "title": "Appendix A — Course Syllabus",
    "section": "\nA.11 COVID policy",
    "text": "A.11 COVID policy\nCOVID-19 safety guidelines and recommendations continue to evolve. Please read Pitzer’s COVID Policies and visit the Student Health Services (SHS) COVID page for the latest campus information and guidance.\n\n\nSneezeCFD\n\nAll applicable campus and LA County policies will apply in this class and I will follow them to the extent feasible. Mask wearing is optional under Pitzer and LA County guidelines, and therefore it is in this classroom as well. If you need to sneeze, cover up with an elbow…\nIf we do have a COVID breakout or otherwise require hybrid/remote class environments through Zoom, I will post meeting links via email.",
    "crumbs": [
      "Home",
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Course Syllabus</span>"
    ]
  },
  {
    "objectID": "syllabus.html#readings",
    "href": "syllabus.html#readings",
    "title": "Appendix A — Course Syllabus",
    "section": "\nA.12 Readings",
    "text": "A.12 Readings\nThe theory of environmental data visualization will use selected readings assigned to students. Every other class will involve a discussion of an assigned reading or analysis of an environmental data visualization.\nAssigned readings will include selections from books, peer-review journal articles, websites, and newspaper articles. A selection of readings that are likely to be discussed in the course includes:\n\nSelections from Tufte’s book ‘The Visual Display of Quantitative Information’ (Tufte 2001)\n\nSelections from Tufte’s book ‘Envisioning Information’ (Tufte 2013)\n\nSelections from Hadley Wickham’s “Grammar of Graphics” with ggplot2, shiny, and other R packages. (Wickham et al. 2019)\n\nA selection of Peer-review journal articles listed in the references below. (Horton, Nowak, and Haegeli 2020; Kelleher and Wagener 2011; van Beek et al. 2020; Gommeh, Dijstelbloem, and Metze 2021; Murchie and Diomede 2020; Grainger, Mao, and Buytaert 2016)\n\nNewspaper articles such as the LA Times article by Professor Phillips on Inland Empire Warehouse growth (Facebook et al. 2022)\n\nReadings on the meaning, use, and technical limitations of Environmental Justice tools\n\n\n\n\n\n\n\n\n\n\n\n\n\nFacebook, Twitter, Show more sharing options, Facebook, Twitter, LinkedIn, Email, Copy Link URLCopied!, and Print. 2022. “Op-Ed: We Mapped the Warehouse Takeover of the Inland Empire. The Results Are Overwhelming.” Los Angeles Times. https://www.latimes.com/opinion/story/2022-05-01/inland-empire-warehouse-growth-map-environment.\n\n\nGommeh, Efrat, Huub Dijstelbloem, and Tamara Metze. 2021. “Visual Discourse Coalitions: Visualization and Discourse Formation in Controversies over Shale Gas Development.” Journal of Environmental Policy & Planning 23 (3): 363–80. https://doi.org/10.1080/1523908X.2020.1823208.\n\n\nGrainger, Sam, Feng Mao, and Wouter Buytaert. 2016. “Environmental Data Visualisation for Non-Scientific Contexts: Literature Review and Design Framework.” Environmental Modelling & Software 85 (November): 299–318. https://doi.org/10.1016/j.envsoft.2016.09.004.\n\n\nHorton, Simon, Stan Nowak, and Pascal Haegeli. 2020. “Enhancing the Operational Value of Snowpack Models with Visualization Design Principles.” Natural Hazards and Earth System Sciences 20 (6): 1557–72. https://doi.org/10.5194/nhess-20-1557-2020.\n\n\nKelleher, Christa, and Thorsten Wagener. 2011. “Ten Guidelines for Effective Data Visualization in Scientific Publications.” Environmental Modelling & Software 26 (6): 822–27. https://doi.org/10.1016/j.envsoft.2010.12.006.\n\n\nMurchie, Karen J., and Dylan Diomede. 2020. “Fundamentals of Graphic Designessential Tools for Effective Visual Science Communication.” FACETS 5 (1): 409–22. https://doi.org/10.1139/facets-2018-0049.\n\n\nTufte, Edward R. 2001. The Visual Display of Quantitative Information, 2nd Ed. 2nd edition. Cheshire, Conn: Graphics Press.\n\n\n———, ed. 2013. Envisioning Information. 14. print. Cheshire, Conn: Graphics Press.\n\n\nvan Beek, Lisette, Tamara Metze, Eva Kunseler, Hiddo Huitzing, Filip de Blois, and Arjan Wardekker. 2020. “Environmental Visualizations: Framing and Reframing Between Science, Policy and Society.” Environmental Science & Policy 114 (December): 497–505. https://doi.org/10.1016/j.envsci.2020.09.011.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain FranÃois, Garrett Grolemund, et al. 2019. “Welcome to the tidyverse.” Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.",
    "crumbs": [
      "Home",
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Course Syllabus</span>"
    ]
  },
  {
    "objectID": "tools.html",
    "href": "tools.html",
    "title": "Appendix B — R and RStudio Installation and Overview",
    "section": "",
    "text": "B.1 Download and Install R\nR is maintained and made available through the web-page at The Comprehensive R Archive Network aka CRAN.\nThe top of the CRAN web page provides three links for downloading R. Follow the link that describes the OS of your computer: Mac, Windows, or Linux.",
    "crumbs": [
      "Home",
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>R and RStudio Installation and Overview</span>"
    ]
  },
  {
    "objectID": "tools.html#download-and-install-r",
    "href": "tools.html#download-and-install-r",
    "title": "Appendix B — R and RStudio Installation and Overview",
    "section": "",
    "text": "B.1.1 R for macOS\nTo install R on a Mac, click the “Download R for macOS” link. Next, click on the R-4.4.1 package link (or the package link for the most current release of R). An installer will download to guide you through the installation process. As a starting point, I recommend that most users should choose the default installation settings until they are familiar with R.\n\n\nB.1.2 R for Windows\nTo install R on Windows, click the “Download R for Windows” link. Next, click on the install R for the first time link which contains base R. Then click on the link that says Download R-4.4.1 for Windows. A win.exe file will be downloaded to your downloads folder. Open that file after it downloads and follow the installation process. As a starting point, I recommend that most users should choose the default installation settings until they are familiar with R.\n\n\nB.1.3 R for Linux\nR comes preinstalled on many Linux systems, but update to the newest version of R if yours is out of date. The CRAN website provides files for different Linux builds including Debian, Fedora, Redhat, Suse, and Ubuntu. Choose the appropriate directory and the installation procedure for your flavor of Linux.",
    "crumbs": [
      "Home",
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>R and RStudio Installation and Overview</span>"
    ]
  },
  {
    "objectID": "tools.html#about-r",
    "href": "tools.html#about-r",
    "title": "Appendix B — R and RStudio Installation and Overview",
    "section": "B.2 About R",
    "text": "B.2 About R\nR is not a friendly computer program like a web browser or a Microsoft Office product. R is a programming language, like C++, Python, or Java. R can be run like an old-school UNIX terminal, writing commands directly onto monitors with green fonts; imagine Neo in the Matrix or Angelina Jolie in Hackers. While one can still do that, most folks use the RStudio IDE.\n\n\n\nHackers use green fonts and dark mode.",
    "crumbs": [
      "Home",
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>R and RStudio Installation and Overview</span>"
    ]
  },
  {
    "objectID": "tools.html#rstudio-ide",
    "href": "tools.html#rstudio-ide",
    "title": "Appendix B — R and RStudio Installation and Overview",
    "section": "B.3 RStudio IDE",
    "text": "B.3 RStudio IDE\nRStudio is an application - like MS Word or a browser. However, Rstudio is an app that helps you write in “R”, not English. It is literally a foreign language (unless you know it already). And just like any language, R has its own syntax, grammar, and vocabulary. It takes training and time to learn R, but I believe it is worth it.\nWe will use RStudio in this course because it makes using R much easier. Also, the RStudio interface looks about the same for different operating systems, which will help me because I am a Windows user and I’ve observed that Claremont Colleges’ scholars tend to lean towards macOS.\nDownload RStudio desktop here - I recommend the free open source version. Make sure to pick the version that is appropriate for your OS. Then follow the installation instructions.\nOnce installed, RStudio can be opened like any other program or app on your computer; usually just click on the icon on the desktop. When you open it, it should look something like Figure D.1.\n\n\n\n\n\n\nFigure B.1: RStudio\n\n\n\nHere, there are four separate windows or “Panels”.\n\nThe source panel is top-left and this is basically a text editor where you type R code or regular text. Code here gets colored and looks different if it is doing various R things. More on this later. Code doesn’t get immediately executed here; it is more like a holding place for writing/testing/debugging bigger “scripts” or programs.\nThe console/terminal is bottom-left. The terminal is the 1980s window that does commands directly. Type print(‘Hello World’), press enter/return, and you’ve written some code. This console is what R would look like if you ran it without RStudio.\nThe top-right is the file manager panel. It shows files in your directory, plots, packages, and help files.\nThe bottom-right is the programming environment. It contains things you’ve loaded or coded. Right now it should be empty because you’ve done neither.\n\nOf course all of these can be moved around to match how you like to set it up. And I need a different color-scheme than the ugly default.\nSelect the Tools menu, followed by Global Options in the dropdown Tools menu. Navigate to appearance and you should be able to alter the color scheme to something more your style. My preferred style is Merbivore Soft as shown in Figure B.2.\n\n\n\n\n\n\nFigure B.2: goodRstudio\n\n\n\n\n\n\n\n\n\nDo I still need to download R?\n\n\n\nEven if you use RStudio, you’ll still need to download R to your computer (or use R and RStudio cloud versions). RStudio helps you use the version of R that lives on your computer, but it doesn’t come with a version of R on its own.\nI recommend downloading R and RStudio for compatibility, but the RStudio Cloud does exist and does mostly the same thing. I will be less helpful at supporting the Cloud version for this class.\nIn this class, I will be testing out web assembly live versions that allow executable code within the browser. This will remove version control and package issues, since it will live within the browser when posted. Check each coding lesson for Noodle Zone areas to work within the browser if your code is not working on your local machine.",
    "crumbs": [
      "Home",
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>R and RStudio Installation and Overview</span>"
    ]
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Appendix C — Resources",
    "section": "",
    "text": "Base R is the collection of functions that come preloaded with R. A function is a code block that performs a task. Functions that come in R are in-built functions. However, the real power of R (and programming languages more generally) are the large number of user-built functions that are built to perform tasks that can be loaded into base R.\nSets of functions that have a common purpose are bundled together in R in “packages”. There are literally thousands of packages custom-built for R.\nDuring this course, I will ask you to use some important packages for data acquisition, tidying, and visualization. There are two steps to using a package in R.\nFirst, it needs to be installed. Here’s a non-functional example.\n\ninstall.packages('&lt;PACKAGE.NAME&gt;')\n\nAnd this example will install an actual package called janitor. This package features a nice import function that fixes column names on import called clean_names().\n\ninstall.packages('janitor')\n\nIn a meta way, you now have used a function to install a package. ‘install.package()’ is an example of an in-built R function.\nOnce a package is installed, it needs to be loaded. While the installation has put the package on your computer, you need to tell R that it should load these functions for use.\n\n\n\n\n\n\nR and other programming languages only do EXACTLY what they are told to do.\n\n\n\nLoading a package is accomplished by calling base R library function. Success is indicated with a message like “Attaching package: ‘janitor’\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\nLibraries have to be loaded each time you restart your R session. The current libraries loaded can be founded in the file manager panel under the Packages tab.\n\nC.0.1 Color Resources\nCourtesy of Dalai Vo - Fall 2022 EA 078 student - a color palette cheatsheet",
    "crumbs": [
      "Home",
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "debugging.html",
    "href": "debugging.html",
    "title": "Appendix D — Debugging Steps",
    "section": "",
    "text": "D.1 Is there a typo?\nRunning any line of code or code block will fail if there is a typo.\nCheck for:",
    "crumbs": [
      "Home",
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Debugging Steps</span>"
    ]
  },
  {
    "objectID": "debugging.html#is-there-a-typo",
    "href": "debugging.html#is-there-a-typo",
    "title": "Appendix D — Debugging Steps",
    "section": "",
    "text": "typos or misspelling of variables, functions,\ncapitalization\nmissing punctuation (parenthesis, comma, pipe, +)",
    "crumbs": [
      "Home",
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Debugging Steps</span>"
    ]
  },
  {
    "objectID": "debugging.html#is-the-packagelibrary-installed-and-loaded",
    "href": "debugging.html#is-the-packagelibrary-installed-and-loaded",
    "title": "Appendix D — Debugging Steps",
    "section": "D.2 Is the package/library installed and loaded?",
    "text": "D.2 Is the package/library installed and loaded?\nIf you are calling a function, the library needs to be installed and loaded (or called explicitly).\n\nCheck if the library is loaded in the Files, Plots, Packages... under the Packages tab. A package is loaded if there is a checkmark by it.\nCheck if the package is installed. Same procedure as above, but the package won’t even be listed if it isn’t installed.\nCall the package explicitly using the syntax &lt;PACKAGE.NAME&gt;::&lt;FUNCTION.NAME&gt;. An example would be janitor::clean_names().\n\nIf you don’t know where the panels are - see this image and description. We’ll use it a few times.\n\n\n\n\n\n\nFigure D.1: RStudio\n\n\n\nHere, there are four separate windows or “Panels”.\n\nThe source panel is top-left and this is basically a text editor where you type R code or regular text. Code here gets colored and looks different if it is doing various R things. More on this later. Code doesn’t get immediately executed here; it is more like a holding place for writing/testing/debugging bigger “scripts” or programs.\nThe console/terminal is bottom-left. The terminal is the 1980s window that does commands directly. Type print(‘Hello World’), press enter/return, and you’ve written some code. This console is what R would look like if you ran it without RStudio.\nThe top-right is the file manager or Files, Plots, Packages... panel. It shows files in your directory, plots, packages, and help files.\nThe bottom-right is the programming environment or Environment panel. It contains things you’ve loaded or coded. Right now it should be empty because you’ve done neither.",
    "crumbs": [
      "Home",
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Debugging Steps</span>"
    ]
  },
  {
    "objectID": "debugging.html#is-the-data-loaded-in-the-global-environment",
    "href": "debugging.html#is-the-data-loaded-in-the-global-environment",
    "title": "Appendix D — Debugging Steps",
    "section": "D.3 Is the data loaded in the global environment?",
    "text": "D.3 Is the data loaded in the global environment?\nThe data needs to be imported and loaded into the global environment before it can be manipulated.\n\nCheck the Environment panel to see if the dataset of interest is loaded and named as expected.",
    "crumbs": [
      "Home",
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Debugging Steps</span>"
    ]
  },
  {
    "objectID": "debugging.html#is-the-syntax-correct",
    "href": "debugging.html#is-the-syntax-correct",
    "title": "Appendix D — Debugging Steps",
    "section": "D.4 Is the syntax correct?",
    "text": "D.4 Is the syntax correct?\nThe syntax for the code needs to be correct, and needs to follow the idiomatic rules of R.\n\nShould it be a pipe |&gt; or a +?\nDoes the function include all required arguments?\nDid I pass in the data?",
    "crumbs": [
      "Home",
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Debugging Steps</span>"
    ]
  },
  {
    "objectID": "debugging.html#does-a-simpler-version-work",
    "href": "debugging.html#does-a-simpler-version-work",
    "title": "Appendix D — Debugging Steps",
    "section": "D.5 Does a simpler version work?",
    "text": "D.5 Does a simpler version work?\nWhen coding in class, we’ll often start simple, then add complexity for our visualization code. The reason for that is to make sure the very basic things are all there and working, and also because it makes debugging much simpler.\nIf a long piece of code breaks, try to see if a minimum reproducible example does work. This is standard for trouble-shooting to make sure none of the previous four things are the problem. Try to make it a single line of code with the most basic functionality and see if that works. Then add one line at a time to see where things break.",
    "crumbs": [
      "Home",
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Debugging Steps</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Facebook, Twitter, Show more sharing options, Facebook, Twitter,\nLinkedIn, Email, Copy Link URLCopied!, and Print. 2022.\n“Op-Ed: We Mapped the Warehouse Takeover\nof the Inland Empire. The Results Are\nOverwhelming.” Los Angeles Times.\nhttps://www.latimes.com/opinion/story/2022-05-01/inland-empire-warehouse-growth-map-environment.\n\n\nGommeh, Efrat, Huub Dijstelbloem, and Tamara Metze. 2021. “Visual\nDiscourse Coalitions: Visualization and Discourse Formation in\nControversies over Shale Gas Development.” Journal of\nEnvironmental Policy & Planning 23 (3): 363–80. https://doi.org/10.1080/1523908X.2020.1823208.\n\n\nGrainger, Sam, Feng Mao, and Wouter Buytaert. 2016. “Environmental\nData Visualisation for Non-Scientific Contexts: Literature\nReview and Design Framework.” Environmental Modelling &\nSoftware 85 (November): 299–318. https://doi.org/10.1016/j.envsoft.2016.09.004.\n\n\nHorton, Simon, Stan Nowak, and Pascal Haegeli. 2020. “Enhancing\nthe Operational Value of Snowpack Models with Visualization Design\nPrinciples.” Natural Hazards and Earth System Sciences\n20 (6): 1557–72. https://doi.org/10.5194/nhess-20-1557-2020.\n\n\nKelleher, Christa, and Thorsten Wagener. 2011. “Ten Guidelines for\nEffective Data Visualization in Scientific Publications.”\nEnvironmental Modelling & Software 26 (6): 822–27. https://doi.org/10.1016/j.envsoft.2010.12.006.\n\n\nMurchie, Karen J., and Dylan Diomede. 2020. “Fundamentals of\nGraphic Designessential Tools for Effective Visual Science\nCommunication.” FACETS 5 (1): 409–22. https://doi.org/10.1139/facets-2018-0049.\n\n\nTufte, Edward R. 2001. The Visual Display of\nQuantitative Information, 2nd Ed. 2nd\nedition. Cheshire, Conn: Graphics Press.\n\n\n———, ed. 2013. Envisioning Information. 14. print.\nCheshire, Conn: Graphics Press.\n\n\nvan Beek, Lisette, Tamara Metze, Eva Kunseler, Hiddo Huitzing, Filip de\nBlois, and Arjan Wardekker. 2020. “Environmental Visualizations:\nFraming and Reframing Between Science, Policy and\nSociety.” Environmental Science & Policy 114\n(December): 497–505. https://doi.org/10.1016/j.envsci.2020.09.011.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy\nD’Agostino McGowan, Romain FranÃois, Garrett Grolemund, et al. 2019.\n“Welcome to the tidyverse.”\nJournal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.",
    "crumbs": [
      "Home",
      "Appendices",
      "References"
    ]
  },
  {
    "objectID": "weather.html",
    "href": "weather.html",
    "title": "Unit 1: Introduction to Data Visualization",
    "section": "",
    "text": "The most common environmental dataset that people encounter is the weather. Every major type of media devotes time to the weather: newspapers, news shows, apps, twitter bots, and The Weather Channel.\nIt is a great example for us to start talking about environmental data. Additionally, the weather is often confused for the Climate. Given the existential threat of Climate Change, we’ll explore, replicate, and maybe improve some climate visualizations.\n\nComparative Analysis\nExamine Figure 1 from the Los Angeles Times, a Twitter emoji weather map, and a screenshot from Wunderground.\n\n\n\n\n\n\nWhat are your impressions of these different visualizations?\n\n\n\n\n\n\n\n\n\nFigure 1: Los Angeles Times Weather Map\n\n\n\n\n\n\n\n\n\nFigure 2: Twitter emoji Map\n\n\n\n\n\n\n\n\n\nFigure 3: Wunderground weather website and app",
    "crumbs": [
      "Home",
      "Unit 1: Introduction to Data Visualization"
    ]
  },
  {
    "objectID": "EJ.html",
    "href": "EJ.html",
    "title": "Unit 2: Environmental Justice",
    "section": "",
    "text": "This unit focuses on the identification and quantification of the unequal distribution and access to natural resources within California and the United States - Environmental Justice",
    "crumbs": [
      "Home",
      "Unit 2: Environmental Justice"
    ]
  }
]